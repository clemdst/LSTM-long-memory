{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ee5ef4",
   "metadata": {},
   "source": [
    "In this notebbok, we prove that LSTM fail into capturing long memory in multivariate time series. \n",
    "\n",
    "Then, we applied the two complementary tests detailed in the paper *A Statistical Investigation of Long Memory in Language and Music* by Greaves-Tunnell, Alexander and Harchaoui, Zaid.\n",
    "\n",
    "The two tests consists into checking the GSE statistics of the long memory vector d in the last hidden layer of the trained LSTM. \n",
    "\n",
    "The difference between the two tests: the first test consists into training the LSTM on a Fractionnaly differenced WN while the second test consists into training the LSTM on a WN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from _varfima import sim_VARFIMA, sim_FD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671b492",
   "metadata": {},
   "source": [
    "# Test 1: Integration of Fractionnaly Differenced WN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e08af",
   "metadata": {},
   "source": [
    "##### Generation of a random Fractionally Differenced White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's generate a random long memory paramater vector (d)\n",
    "\n",
    "np.random.seed(42)\n",
    "k= 200 #number of time series \n",
    "d_min, d_max = 0.05, 0.45  # to have a long memory vector parameter (d in ]0,0.5[**p)\n",
    "d = torch.tensor(np.random.uniform(d_min, d_max, size=k), dtype=torch.float32)\n",
    "\n",
    "#Then let's generated a fractionnally differenced white noise based on the generated d vector, of length T\n",
    "T=2**16 #same length as in the paper\n",
    "FD_seq, _ = sim_FD(T=2**16, k=200, d=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5587d",
   "metadata": {},
   "source": [
    "### Let's build a LSTM with two layers for multivariate time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd2c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's build the LSTM model for time series prediction\n",
    "\n",
    "class LSTMPredictor(nn.Module):\n",
    "    \"\"\"LSTM for time series prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, \n",
    "                 dropout=0.2, forecast_horizon=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size: Number of features (k variables)\n",
    "            hidden_size: Size of the hidden state\n",
    "            num_layers: Number of layers in the LSTM\n",
    "            dropout: Dropout rate between LSTM layers\n",
    "            forecast_horizon: Number of time steps to predict\n",
    "        \"\"\"\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        # Couche LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True  # (batch, seq, feature)\n",
    "        )\n",
    "        \n",
    "        # Couche fully connected pour la prédiction\n",
    "        self.fc = nn.Linear(hidden_size, input_size * forecast_horizon)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_length, input_size)\n",
    "        Returns:\n",
    "            predictions: (batch, forecast_horizon, input_size)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # LSTM forward\n",
    "        # lstm_out: (batch, seq_length, hidden_size)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Prendre la dernière sortie temporelle\n",
    "        last_output = lstm_out[:, -1, :]  # (batch, hidden_size)\n",
    "        \n",
    "        # Prédiction\n",
    "        predictions = self.fc(last_output)  # (batch, input_size*forecast_horizon)\n",
    "        \n",
    "        # Reshape pour séparer forecast_horizon et input_size\n",
    "        predictions = predictions.view(batch_size, self.forecast_horizon, \n",
    "                                      self.input_size)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "k=200\n",
    "\n",
    "#Let's load the built LSTM model of two layers adapted to our multivariate time series of size k=200\n",
    "lstm_model = LSTMPredictor(\n",
    "    input_size=k,           \n",
    "    hidden_size=64,        \n",
    "    dropout=0.2,           \n",
    "    forecast_horizon=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95184d3c",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7d96cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VARFIMADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, seq_length=50, forecast_horizon=1):\n",
    "        self.data = data.T  # (T, k)\n",
    "        self.seq_length = seq_length\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_length - self.forecast_horizon + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Input: [idx : idx+seq_length]\n",
    "        X = self.data[idx:idx+self.seq_length]\n",
    "        \n",
    "        # Target: [idx+seq_length : idx+seq_length+forecast_horizon]\n",
    "        y = self.data[idx+self.seq_length:\n",
    "                      idx+self.seq_length+self.forecast_horizon]\n",
    "        \n",
    "        return X.float(), y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5cee7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prepared dataset:\n",
      "  - Train samples: 52388\n",
      "  - Val samples: 13098\n",
      "  - Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "#Let's prepare the dataset of training and validation\n",
    "dataset = VARFIMADataset(FD_seq, seq_length=50, forecast_horizon=1)\n",
    "X_test, y_test = dataset[0]  # Doit fonctionner\n",
    "\n",
    "\n",
    "# Split train/validation \n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\" Prepared dataset:\")\n",
    "print(f\"  - Train samples: {len(train_dataset)}\")\n",
    "print(f\"  - Val samples: {len(val_dataset)}\")\n",
    "print(f\"  - Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20dd8a",
   "metadata": {},
   "source": [
    "##### Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8cca3086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement sur cpu\n",
      "==================================================\n",
      "Epoch [5/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [10/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [15/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [20/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [25/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [30/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [35/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [40/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [45/50] Train Loss: nan | Val Loss: nan\n",
      "Epoch [50/50] Train Loss: nan | Val Loss: nan\n",
      "==================================================\n",
      "✓ Entraînement terminé!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modèle sauvegardé: lstm_varfima_model.pth\n"
     ]
    }
   ],
   "source": [
    "#Let's train the LSTM on the generated data using a ADAM optimizer and MSE loss\n",
    "\n",
    "# Configuration \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = lstm_model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5) #automatic learning rate adjustment\n",
    "\n",
    "num_epochs = 50 #50 iterations\n",
    "\n",
    "# Historique des pertes\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"Entraînement sur {device}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # === TRAINING ===\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # === VALIDATION ===\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            predictions = model(X_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Affichage\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"✓ Entraînement terminé\")\n",
    "\n",
    "# Visualisation of loss \n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.title('Training History')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Let's save the trained model\n",
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_loss': train_losses[-1],\n",
    "    'val_loss': val_losses[-1],\n",
    "}, 'lstm_varfima_model.pth')\n",
    "\n",
    "print(\"✓ Modèle sauvegardé: lstm_varfima_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405fe1a",
   "metadata": {},
   "source": [
    "#### Let's verify the long memory property in the LSTM trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523d901c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des sorties LSTM: (52388, 50, 64)\n",
      "Shape pour analyse: (64, 2619400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger le modèle entrainé \n",
    "model = LSTMPredictor(\n",
    "    input_size=k,           \n",
    "    hidden_size=64,        \n",
    "    dropout=0.2,           \n",
    "    forecast_horizon=1) \n",
    "model.load_state_dict(torch.load('lstm_varfima_model.pth')[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# Extraire les sorties LSTM pour tous les batchs\n",
    "def extract_lstm_outputs_from_loader(model, train_loader):\n",
    "    \"\"\"\n",
    "    Extrait les sorties du LSTM pour toutes les données du train_loader\n",
    "    \"\"\"\n",
    "    all_lstm_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            # batch_X shape: (batch_size, seq_len, input_size)\n",
    "            h0 = torch.zeros(model.num_layers, batch_X.size(0), model.hidden_size)\n",
    "            c0 = torch.zeros(model.num_layers, batch_X.size(0), model.hidden_size)\n",
    "            \n",
    "            # Obtenir les sorties LSTM\n",
    "            lstm_out, _ = model.lstm(batch_X, (h0, c0))\n",
    "            \n",
    "            # lstm_out shape: (batch_size, seq_len, hidden_size)\n",
    "            all_lstm_outputs.append(lstm_out.numpy())\n",
    "    \n",
    "    # Concaténer tous les batchs\n",
    "    all_outputs = np.concatenate(all_lstm_outputs, axis=0)  # (total_samples, seq_len, hidden_size)\n",
    "    \n",
    "    return all_outputs\n",
    "\n",
    "# Extraire les sorties\n",
    "lstm_outputs = extract_lstm_outputs_from_loader(model, train_loader)\n",
    "print(f\"Shape des sorties LSTM: {lstm_outputs.shape}\")  # (n_samples, seq_len, hidden_size)\n",
    "\n",
    "#  Créer une séquence temporelle à partir des sorties: Prendre toutes les séquences et les concaténer temporellement\n",
    "# Chaque neurone caché devient une longue série temporelle\n",
    "seq_concatenated = lstm_outputs.transpose(2, 0, 1).reshape(lstm_outputs.shape[2], -1)\n",
    "print(f\"Shape pour analyse: {seq_concatenated.shape}\")  # (hidden_size, n_samples * seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41e9575",
   "metadata": {},
   "source": [
    "We're using an already coded function \"compute_total_memory\" that compute the long memory parameter d, based on a temporal sequence and by using a GSE statistics. Then, this function conducts a test on the long memory on the computed statistics and returns the parameter d estimated and its p-value.\n",
    "\n",
    "More specificially the function is testing H0: d= 0 vs H0: d>0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0501e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analyse de mémoire longue ===\n",
      "Paramètre d moyen: 0.0021\n",
      "Variance asymptotique: 0.003906\n",
      "P-value: 0.4867\n",
      "Mémoire longue significative: NON\n"
     ]
    }
   ],
   "source": [
    "from d_test import compute_total_memory\n",
    "\n",
    "# Test sur le paramètre de mémoire longue d via la statistique GSE\n",
    "tot_mem, asy_var, p_val = compute_total_memory(seq_concatenated)\n",
    "\n",
    "print(f\"\\n=== Analyse de mémoire longue ===\")\n",
    "print(f\"Paramètre d moyen: {tot_mem:.4f}\")\n",
    "print(f\"Variance asymptotique: {asy_var:.6f}\")\n",
    "print(f\"P-value: {p_val:.4f}\")\n",
    "print(f\"Mémoire longue significative: {'OUI' if p_val < 0.05 else 'NON'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f5eb7",
   "metadata": {},
   "source": [
    "# Test 2 (complementary) Long memory transformation of White Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1fe7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation of a WN sequence of length T and size k=200\n",
    "#training of the LSTM model on this WN sequence\n",
    "#computing the statistics of the learned LSTM\n",
    "#checking if d=0 (short memory) or d>0 (long memory)\n",
    "#OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
