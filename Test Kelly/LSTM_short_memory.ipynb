{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "08ee5ef4",
      "metadata": {
        "id": "08ee5ef4"
      },
      "source": [
        "In this notebook, we prove that LSTM fail into capturing long memory in multivariate time series.\n",
        "\n",
        "Then, we applied the two complementary tests detailed in the paper *A Statistical Investigation of Long Memory in Language and Music* by Greaves-Tunnell, Alexander and Harchaoui, Zaid.\n",
        "\n",
        "The two tests consists into checking the GSE statistics of the long memory vector d in the last hidden layer of the trained LSTM.\n",
        "\n",
        "The difference between the two tests: the first test consists into training the LSTM on a Fractionnaly differenced WN while the second test consists into training the LSTM on a WN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4MdKXWJasms0",
      "metadata": {
        "id": "4MdKXWJasms0"
      },
      "outputs": [],
      "source": [
        "#Google collab setting\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"LSTM-long-memory/Test Kelly\")\n",
        "os.chdir(\"LSTM-long-memory/Test Kelly\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f3a6a84",
      "metadata": {
        "id": "6f3a6a84"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from _varfima import sim_VARFIMA, sim_FD\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "torch.manual_seed(42) #For reproductibility\n",
        "from d_test import compute_total_memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cd5587d",
      "metadata": {
        "id": "8cd5587d"
      },
      "source": [
        "##  Building of a LSTM with two layers for multivariate time series prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0bd2c202",
      "metadata": {
        "id": "0bd2c202"
      },
      "outputs": [],
      "source": [
        "#Let's build the LSTM model for time series prediction\n",
        "\n",
        "class LSTMPredictor(nn.Module):\n",
        "    \"\"\"LSTM for time series prediction\"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2,\n",
        "                 dropout=0.2, forecast_horizon=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_size: Number of features (k variables)\n",
        "            hidden_size: Size of the hidden state\n",
        "            num_layers: Number of layers in the LSTM\n",
        "            dropout: Dropout rate between LSTM layers\n",
        "            forecast_horizon: Number of time steps to predict\n",
        "        \"\"\"\n",
        "        super(LSTMPredictor, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.forecast_horizon = forecast_horizon\n",
        "\n",
        "        # Couche LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            batch_first=True  # (batch, seq, feature)\n",
        "        )\n",
        "\n",
        "        # Couche fully connected pour la prédiction\n",
        "        self.fc = nn.Linear(hidden_size, input_size * forecast_horizon)\n",
        "\n",
        "        self.input_size = input_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch, seq_length, input_size)\n",
        "        Returns:\n",
        "            predictions: (batch, forecast_horizon, input_size)\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # LSTM forward\n",
        "        # lstm_out: (batch, seq_length, hidden_size)\n",
        "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
        "\n",
        "        # Prendre la dernière sortie temporelle\n",
        "        last_output = lstm_out[:, -1, :]  # (batch, hidden_size)\n",
        "\n",
        "        # Prédiction\n",
        "        predictions = self.fc(last_output)  # (batch, input_size*forecast_horizon)\n",
        "\n",
        "        # Reshape pour séparer forecast_horizon et input_size\n",
        "        predictions = predictions.view(batch_size, self.forecast_horizon,\n",
        "                                      self.input_size)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "k=200"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b4676a",
      "metadata": {
        "id": "92b4676a"
      },
      "source": [
        "## Test 1: Integration of Fractionnaly Differenced WN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e8a2fa",
      "metadata": {
        "id": "33e8a2fa"
      },
      "source": [
        "##### Generation of a random Fractionally Differenced White Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "90745560",
      "metadata": {
        "id": "90745560"
      },
      "outputs": [],
      "source": [
        "# First let's generate a random long memory paramater vector (d)\n",
        "np.random.seed(42)\n",
        "k= 200 #number of time series\n",
        "d_min, d_max = 0.05, 0.45  # to have a long memory vector parameter (d in ]0,0.5[**p)\n",
        "d = torch.tensor(np.random.uniform(d_min, d_max, size=k), dtype=torch.float32)\n",
        "\n",
        "#Then let's generated a fractionnally differenced white noise based on the generated d vector, of length T\n",
        "T=2**16 #same length as in the paper, and same number k of time series\n",
        "FD_seq, _ = sim_FD(T=2**16, k=200, d=d)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95184d3c",
      "metadata": {
        "id": "95184d3c"
      },
      "source": [
        "##### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "afcb7a56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afcb7a56",
        "outputId": "3a3ee81c-8656-4403-a293-e6f2543095fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 65536])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "FD_seq.shape #we have a non supervised dataset of shape (k,T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f7d96cff",
      "metadata": {
        "id": "f7d96cff",
        "outputId": "ece2bd68-5ff8-42a2-b1e9-b2c509cf3e34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Set device for GPU acceleration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def unfold_sequence_to_supervised_dataset(data, seq_length, forecast_horizon=1, device='cpu'):\n",
        "    \"\"\"\n",
        "    Create a supervised dataset from multivariate time series sequence.\n",
        "    with a rolling window approach.\n",
        "    Args:\n",
        "        data: torch.Tensor of shape (k, T)\n",
        "        seq_length: length of the input window (size of X)\n",
        "        forecast_horizon: number of steps to predict (size of y)\n",
        "\n",
        "    Returns:\n",
        "        X: (n_samples, seq_length, k)\n",
        "        y: (n_samples, forecast_horizon, k)\n",
        "    \"\"\"\n",
        "    data = data.to(device).T  # (T, k) on specified device\n",
        "    T, k = data.shape\n",
        "\n",
        "    n_samples = T - seq_length - forecast_horizon + 1\n",
        "\n",
        "    X = torch.zeros((n_samples, seq_length, k), device=device)\n",
        "    y = torch.zeros((n_samples, forecast_horizon, k), device=device)\n",
        "\n",
        "    for idx in range(n_samples):\n",
        "        X[idx] = data[idx:idx+seq_length]\n",
        "        y[idx] = data[idx+seq_length:idx+seq_length+forecast_horizon]\n",
        "\n",
        "    return X.float(), y.float()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9a4cfc",
      "metadata": {
        "id": "ad9a4cfc"
      },
      "source": [
        "We transform our generated time serie into a supervised learning dataset thanks to a rolling window of length 256, so the long memory can be visible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9c055e23",
      "metadata": {
        "id": "9c055e23",
        "outputId": "4ace4c7c-64c6-44c7-e616-944566830203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test 1 dataset created on cuda\n",
            "  y memory: 0.05 GB\n",
            "  X memory: 13.37 GB\n"
          ]
        }
      ],
      "source": [
        "dataset = unfold_sequence_to_supervised_dataset(FD_seq, seq_length=256, forecast_horizon=1, device=device)\n",
        "\n",
        "print(f\"\\nTest 1 dataset created on {device}\")\n",
        "print(f\"  y memory: {dataset[1].element_size() * dataset[1].nelement() / 1e9:.2f} GB\")\n",
        "print(f\"  X memory: {dataset[0].element_size() * dataset[0].nelement() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "36ca3571",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ca3571",
        "outputId": "2e7118f9-aa0b-4259-adae-71e80eef3b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X: torch.Size([65280, 256, 200]) \n",
            "Size of y: torch.Size([65280, 1, 200])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Size of X: {dataset[0].shape} \\nSize of y: {dataset[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a5cee7a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5cee7a9",
        "outputId": "d3d746d8-e682-44ac-a3d1-945a6ab21f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Prepared dataset:\n",
            "  - Train samples: 52224\n",
            "  - Val samples: 13056\n",
            "  - Batch size: 32\n"
          ]
        }
      ],
      "source": [
        "#Let's prepare the dataset of training and validation\n",
        "\n",
        "#tensorisation of the dataset\n",
        "full_dataset= torch.utils.data.TensorDataset(dataset[0], dataset[1])\n",
        "\n",
        "# Split train/validation\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, val_size]\n",
        ")\n",
        "\n",
        "# Batching\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\" Prepared dataset:\")\n",
        "print(f\"  - Train samples: {len(train_dataset)}\")\n",
        "print(f\"  - Val samples: {len(val_dataset)}\")\n",
        "print(f\"  - Batch size: {batch_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a20dd8a",
      "metadata": {
        "id": "1a20dd8a"
      },
      "source": [
        "##### Data Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8cca3086",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "8cca3086",
        "outputId": "0c006dc9-a834-40b8-f263-874f107f39d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entraînement sur cuda\n",
            "==================================================\n",
            "Epoch [5/120] Train Loss: 1.158615 | Val Loss: 1.152245\n",
            "Epoch [10/120] Train Loss: 1.147575 | Val Loss: 1.145534\n",
            "Epoch [15/120] Train Loss: 1.142960 | Val Loss: 1.141181\n",
            "Epoch [20/120] Train Loss: 1.140806 | Val Loss: 1.140041\n",
            "Epoch [25/120] Train Loss: 1.139713 | Val Loss: 1.139442\n",
            "Epoch [30/120] Train Loss: 1.138537 | Val Loss: 1.138243\n",
            "Epoch [35/120] Train Loss: 1.137739 | Val Loss: 1.138206\n",
            "Epoch [40/120] Train Loss: 1.119763 | Val Loss: 1.125434\n",
            "Epoch [45/120] Train Loss: 1.115661 | Val Loss: 1.123160\n",
            "Epoch [50/120] Train Loss: 1.113963 | Val Loss: 1.122099\n",
            "Epoch [55/120] Train Loss: 1.112421 | Val Loss: 1.121441\n",
            "Epoch [60/120] Train Loss: 1.111305 | Val Loss: 1.120715\n",
            "Epoch [65/120] Train Loss: 1.110442 | Val Loss: 1.120191\n",
            "Epoch [70/120] Train Loss: 1.109726 | Val Loss: 1.119810\n",
            "Epoch [75/120] Train Loss: 1.107327 | Val Loss: 1.119013\n",
            "Epoch [80/120] Train Loss: 1.106501 | Val Loss: 1.118694\n",
            "Epoch [85/120] Train Loss: 1.106111 | Val Loss: 1.118540\n",
            "Epoch [90/120] Train Loss: 1.105877 | Val Loss: 1.118450\n",
            "Epoch [95/120] Train Loss: 1.105779 | Val Loss: 1.118369\n",
            "Epoch [100/120] Train Loss: 1.105324 | Val Loss: 1.118222\n",
            "Epoch [105/120] Train Loss: 1.105311 | Val Loss: 1.118214\n",
            "Epoch [110/120] Train Loss: 1.105338 | Val Loss: 1.118214\n",
            "Epoch [115/120] Train Loss: 1.105225 | Val Loss: 1.118215\n",
            "Epoch [120/120] Train Loss: 1.105270 | Val Loss: 1.118216\n",
            "==================================================\n",
            "✓ Entraînement terminé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAGJCAYAAABmacmGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAeQxJREFUeJzt3Xd8VFX+//HXnZ4eAklogdA7yIIi2FDpir0hKlh+7ipWdL+Kiwq6q6uuirqKq/tVvqhgB3tBFBALChoUpEqHhBJITyaTmfv74yYDMQESSDKT4f18PO5jZu6ce+czOYB5e8491zBN00RERERERESOii3UBYiIiIiIiEQChSsREREREZE6oHAlIiIiIiJSBxSuRERERERE6oDClYiIiIiISB1QuBIREREREakDClciIiIiIiJ1QOFKRERERESkDihciYiIiIiI1AGFKxERCbnx48eTnp5+RMdOmTIFwzDqtqB6smnTJgzDYMaMGaEuRURE6oHClYiIHJRhGDXaFixYEOpSQ2L8+PHExsYe9H3DMLjpppuO+nOee+45BTIRkUbAEeoCREQkfL3yyiuVXs+cOZN58+ZV2d+tW7ej+pwXX3yRQCBwRMdOnjyZu++++6g+v6G0bduW4uJinE5nrY577rnnaNasGePHj6+fwkREpE4oXImIyEFdccUVlV5///33zJs3r8r+PyoqKiI6OrrGn1PbsHEgh8OBw9E4/nNmGAYejyfUZQBQUlKCy+XCZtMkFhGRuqJ/UUVE5KgMHjyYnj17smzZMk499VSio6O55557AHjvvfc466yzaNmyJW63mw4dOvDggw/i9/srneOP11xVXJv0r3/9ixdeeIEOHTrgdrs5/vjj+fHHHysdW901VxXT8ebOnUvPnj1xu9306NGDTz/9tEr9CxYsoH///ng8Hjp06MB//vOferuOq7prrrKysrj66qtp3bo1brebFi1acO6557Jp0yYA0tPTWblyJQsXLgxOwxw8eHDw+A0bNnDxxReTlJREdHQ0J554Ih999FGV72gYBq+//jqTJ0+mVatWREdHk5GRgWEYPPnkk1Vq/fbbbzEMg9mzZ9f5z0FEJFI1jv/VJyIiYS07O5uRI0dy2WWXccUVV5CamgrAjBkziI2NZeLEicTGxvLll19y3333kZeXx2OPPXbY886aNYv8/Hz+/Oc/YxgGjz76KBdccAEbNmw47GjX4sWLeffdd7nxxhuJi4vj6aef5sILL2TLli00bdoUgJ9//pkRI0bQokULpk6dit/v54EHHiA5OblW33/Pnj21an+gCy+8kJUrV3LzzTeTnp7Orl27mDdvHlu2bCE9PZ1p06Zx8803Exsby9/+9jeA4M93586dDBo0iKKiIm655RaaNm3K//3f/3HOOefw9ttvc/7551f6rAcffBCXy8Wdd96J1+ula9eunHTSSbz22mvcfvvtldq+9tprxMXFce655x7xdxMROeaYIiIiNTRhwgTzj//pOO2000zAfP7556u0LyoqqrLvz3/+sxkdHW2WlJQE940bN85s27Zt8PXGjRtNwGzatKm5d+/e4P733nvPBMwPPvgguO/++++vUhNgulwuc/369cF9y5cvNwHzmWeeCe4bPXq0GR0dbW7fvj24b926dabD4ahyzuqMGzfOBA65TZgwocr3evnll03TNM19+/aZgPnYY48d8nN69OhhnnbaaVX233bbbSZgfv3118F9+fn5Zrt27cz09HTT7/ebpmmaX331lQmY7du3r9In//nPf0zAXLVqVXBfaWmp2axZM3PcuHGH/RmIiMh+mhYoIiJHze12c/XVV1fZHxUVFXyen5/Pnj17OOWUUygqKmL16tWHPe+ll15KkyZNgq9POeUUwJoKdzhDhgyhQ4cOwde9e/cmPj4+eKzf7+eLL77gvPPOo2XLlsF2HTt2ZOTIkYc9fwWPx8O8efOq3Q4nKioKl8vFggUL2LdvX40/s8LHH3/MCSecwMknnxzcFxsby/XXX8+mTZv47bffKrUfN25cpT4BuOSSS/B4PLz22mvBfZ999hl79uw57LV1IiJSmaYFiojIUWvVqhUul6vK/pUrVzJ58mS+/PJL8vLyKr2Xm5t72PO2adOm0uuKoFWTIPLHYyuOrzh2165dFBcX07Fjxyrtqtt3MHa7nSFDhtS4/YHcbjePPPIId9xxB6mpqZx44omcffbZXHXVVTRv3vywx2/evJkBAwZU2V+xeuPmzZvp2bNncH+7du2qtE1MTGT06NHMmjWLBx98ELCmBLZq1YozzjjjiL6XiMixSiNXIiJy1P44GgKQk5PDaaedxvLly3nggQf44IMPmDdvHo888ghAjZZet9vt1e43TbNej21It912G2vXruXhhx/G4/Fw77330q1bN37++ec6/6zq+gngqquuYsOGDXz77bfk5+fz/vvvM2bMGK0kKCJSSxq5EhGRerFgwQKys7N59913OfXUU4P7N27cGMKq9ktJScHj8bB+/foq71W3rz516NCBO+64gzvuuIN169Zx3HHH8fjjj/Pqq68CHHTlwrZt27JmzZoq+yumXLZt27ZGnz9ixAiSk5N57bXXGDBgAEVFRVx55ZVH+G1ERI5d+l9SIiJSLypGjg4cKSotLeW5554LVUmVVEznmzt3Ljt27AjuX79+PZ988kmD1FBUVERJSUmlfR06dCAuLg6v1xvcFxMTQ05OTpXjR40axQ8//MB3330X3FdYWMgLL7xAeno63bt3r1EdDoeDMWPG8OabbzJjxgx69epF7969j+xLiYgcwzRyJSIi9WLQoEE0adKEcePGccstt2AYBq+88kpYTcubMmUKn3/+OSeddBI33HADfr+ff//73/Ts2ZOMjIx6//y1a9dy5plncskll9C9e3ccDgdz5sxh586dXHbZZcF2/fr1Y/r06fz973+nY8eOpKSkcMYZZ3D33Xcze/ZsRo4cyS233EJSUhL/93//x8aNG3nnnXdqNa3vqquu4umnn+arr74KTt0UEZHaUbgSEZF60bRpUz788EPuuOMOJk+eTJMmTbjiiis488wzGT58eKjLA6zQ8sknn3DnnXdy7733kpaWxgMPPMCqVatqtJrh0UpLS2PMmDHMnz+fV155BYfDQdeuXXnzzTe58MILg+3uu+8+Nm/ezKOPPkp+fj6nnXYaZ5xxBqmpqXz77bfcddddPPPMM5SUlNC7d28++OADzjrrrFrV0q9fP3r06MGqVasYO3ZsXX9VEZFjgmGG0/9CFBERCQPnnXceK1euZN26daEupUH17duXpKQk5s+fH+pSREQaJV1zJSIix7Ti4uJKr9etW8fHH3/M4MGDQ1NQiCxdupSMjAyuuuqqUJciItJoaeRKRESOaS1atGD8+PG0b9+ezZs3M336dLxeLz///DOdOnUKdXn1bsWKFSxbtozHH3+cPXv2sGHDBjweT6jLEhFplHTNlYiIHNNGjBjB7NmzycrKwu12M3DgQB566KFjIlgBvP322zzwwAN06dKF2bNnK1iJiBwFjVyJiIiIiIjUAV1zJSIiIiIiUgcUrkREREREROqArrmqRiAQYMeOHcTFxWEYRqjLERERERGREDFNk/z8fFq2bHnYm7MrXFVjx44dpKWlhboMEREREREJE1u3bqV169aHbKNwVY24uDjA+gHGx8eHuBrw+Xx8/vnnDBs2DKfTGepypI6oXyOT+jVyqW8jk/o1cqlvI1Mo+jUvL4+0tLRgRjiUkIarRYsW8dhjj7Fs2TIyMzOZM2cO55133kHbv/vuu0yfPp2MjAy8Xi89evRgypQpDB8+PNjm4Ycf5t1332X16tVERUUxaNAgHnnkEbp06VLjuiqmAsbHx4dNuIqOjiY+Pl7/OEQQ9WtkUr9GLvVtZFK/Ri71bWQKZb/W5HKhkC5oUVhYSJ8+fXj22Wdr1H7RokUMHTqUjz/+mGXLlnH66aczevRofv7552CbhQsXMmHCBL7//nvmzZuHz+dj2LBhFBYW1tfXEBERERERCe3I1ciRIxk5cmSN20+bNq3S64ceeoj33nuPDz74gL59+wLw6aefVmozY8YMUlJSWLZsGaeeeupR1ywiIiIiIlKdRn3NVSAQID8/n6SkpIO2yc3NBThkG6/Xi9frDb7Oy8sDrGFHn89XR9UeuYoawqEWqTvq18ikfo1c6tvIpH6NXOrbyBSKfq3NZxmmaZr1WEuNGYZx2Guu/ujRRx/ln//8J6tXryYlJaXK+4FAgHPOOYecnBwWL1580PNMmTKFqVOnVtk/a9YsoqOja1yPiIiIiBw7bDbbYZfmlsbB7/dzsFhUVFTE5ZdfTm5u7mHXY2i0I1ezZs1i6tSpvPfee9UGK4AJEyawYsWKQwYrgEmTJjFx4sTg64oVQYYNGxY2C1rMmzePoUOH6oLMCKJ+jUzq18ilvo1M6tfIVZ996/P52LlzJ8XFxXV6Xjk80zQpKSnB4/HU6f1oDcOgRYsWxMTEVHmvYlZbTTTKcPX6669z3XXX8dZbbzFkyJBq29x00018+OGHLFq06LDr0bvdbtxud5X9TqczrP6hDbd6pG6oXyOT+jVyqW8jk/o1ctV13wYCATZs2IDdbqdVq1a4XK46/SVfDi0QCFBQUEBsbGydjRqapsnu3bvJysqiU6dO2O32Su/X5s9PowtXs2fP5pprruH111/nrLPOqvK+aZrcfPPNzJkzhwULFtCuXbsQVCkiIiIikai0tJRAIEBaWpouHwmBQCBAaWkpHo+nTqdkJicns2nTJnw+X5VwVRshDVcFBQWsX78++Hrjxo1kZGSQlJREmzZtmDRpEtu3b2fmzJmANRVw3LhxPPXUUwwYMICsrCwAoqKiSEhIAKypgLNmzeK9994jLi4u2CYhIYGoqKgG/oYiIiIiEol0rVVkqavRx5D+qVi6dCl9+/YNLqM+ceJE+vbty3333QdAZmYmW7ZsCbZ/4YUXKCsrY8KECbRo0SK43XrrrcE206dPJzc3l8GDB1dq88YbbzTslxMRERERkWNKSEeuBg8efNBVOcC6R9WBFixYcNhzhsnih3Vm/a58Vu3IZbvugSwiIiIiEtY0nhnmZi3Zys2vL2fZHnWViIiIiISX9PR0pk2bFuoywoZ+Yw9zCVHW6iRFZSEuREREREQaLcMwDrlNmTLliM77448/cv311x9VbYMHD+a22247qnOEi0a3WuCxJiHK6qJihSsREREROUKZmZnB52+88Qb33Xcfa9asCe6LjY0NPjdNE7/fj8Nx+KiQnJxct4U2chq5CnMJ0dbIVaHClYiIiEhYMk2TotKykGw1XW+gefPmwS0hIQHDMIKvV69eTVxcHJ988gn9+vXD7XazePFifv/9d84991xSU1OJjY3l+OOP54svvqh03j9OCzQMg//+97+cf/75REdH06lTJ95///2j+vm+88479OjRA7fbTfv27fn3v/9d6f3nnnuOTp064fF4SE1N5aKLLgq+9/bbb9OrVy+ioqJo2rQpQ4YMobCw/hYz0MhVmKuYFljs183pRERERMJRsc9P9/s+C8ln//bAcKJddfMr/d13382//vUv2rdvT5MmTdi6dSujRo3iH//4B263m5kzZzJ69GjWrFlDmzZtDnqeqVOn8uijj/LYY4/xzDPPMHbsWDZv3kxSUlKta1q2bBmXXHIJU6ZM4dJLL2Xx4sXcdNNNtGzZkmuuuYalS5dyyy238MorrzBo0CD27t3L119/DVijdWPGjOHRRx/l/PPPJz8/n6+//rpeF8BTuApzCVEuQNdciYiIiEj9euCBBxg6dGjwdVJSEn369Am+fvDBB5kzZw7vv/8+N91000HPM378eMaMGQPAQw89xNNPP80PP/zAiBEjal3TE088wZlnnsm9994LQMeOHcnIyODxxx/nmmuuYcuWLcTExHD22WcTFxdH27Ztg7d5yszMpKysjAsuuIC2bdsC0KtXr1rXUBsKV2EuOHKlcCUiIiISlqKcdn57YHjIPruu9O/fv9LrgoICpkyZwkcffRQMKsXFxZXuQ1ud3r17B5/HxMQQHx/Prl27jqimVatWce6551bad+KJJ/L888/j9/sZOnQobdu2pX379owYMYIRI0YEpyT26dOHM888k169ejF8+HCGDRvGRRddRJMmTY6olprQNVdh7sBpgf5AZN3DS0RERCQSGIZBtMsRks0w6u7SkZiYmEqv77zzTubMmcNDDz3E119/TUZGBr169aK0tPSQ53E6nVV+PoFAoM7qPFBcXBw//fQTs2fPpkWLFtx333306dOHnJwc7HY78+bN45NPPqF79+4888wzdOnShY0bN9ZLLaBwFfYqwhVAfomGr0RERESkYXzzzTeMHz+e888/n169etG8eXM2bdrUoDV069aNb775ptK+77//ns6dO2O3W6N2DoeDIUOG8Oijj/LLL7+wadMmvvzyS8AKdieddBJTp07l559/xuVyMWfOnHqrV9MCw5zLYSPKaaPYFyC3xEdyQqgrEhEREZFjQadOnXj33XcZPXo0hmFw77331tsI1O7du8nIyKi0r0WLFtxxxx0cf/zxPPjgg1x66aV88803/Pe//w2uGPjhhx+yYcMGTj31VJo0acLHH39MIBCgS5cuLFmyhPnz5zNs2DBSUlJYsmQJu3fvplu3bvXyHUDhqlGIj3JS7POSV+wLdSkiIiIicox44oknuOaaaxg0aBDNmjXjrrvuIi8vr14+a9asWcyaNavSvgcffJDJkyfz5ptvct999/Hggw/SokULJk2axPjx4wFITEzk3XffZcqUKZSUlNCpUydmz55Njx49WLVqFYsWLWLatGnk5eXRtm1bHn/8cUaOHFkv3wEUrhqFBI+TnXlechSuREREROQojR8/PhhOAAYPHlzt8uTp6enB6XUVJkyYUOn1H6cJVneenJycQ9azYMGCQ75/4YUXcuGFFwIQCAQqBbyTTz75oMd369aNTz/99JDnrmu65qoRqLiRcJ6WDBQRERERCVsKV41AgscaYMzVyJWIiIiISNhSuGoE4qMqRq4UrkREREREwpXCVSNQsRx7rpZiFxEREREJWwpXjUB8+bRAjVyJiIiIiIQvhatGIDhypXAlIiIiIhK2FK4agXiFKxERERGRsKdw1QgkRlWsFqhrrkREREREwpXCVSMQXC2wRCNXIiIiIiLhSuGqEUjwVEwL1MiViIiIiITO4MGDue2220JdRthSuGoEEsqnBRZ4y/AHzBBXIyIiIiKNzejRoxkxYkS173399dcYhsEvv/xy1J8zY8YMEhMTj/o8jZXCVSNQMS0QtBy7iIiIiNTetddey7x589i2bVuV915++WX69+9P7969Q1BZZFG4agScdhsumzVipRUDRURERMKMaUJpYWg2s2azms4++2ySk5OZMWNGpf0FBQW89dZbXHvttWRnZzNmzBhatWpFdHQ0vXr1Yvbs2XX6o9qyZQvnnnsusbGxxMfHc8kll7Bz587g+8uXL+f0008nLi6O+Ph4+vXrx9KlSwHYvHkz55xzDunp6cTFxdGjRw8+/vjjOq3vaDlCXYDUTLQDSkshR+FKREREJLz4iuChlqH57Ht2gCvmsM0cDgdXXXUVM2bM4G9/+xuGYQDw1ltv4ff7GTNmDAUFBfTr14+77rqL+Ph4PvroI6688ko6dOjACSeccNSlBgKBYLBauHAhZWVlTJgwgUsvvZQFCxYAMHbsWPr27cv06dOx2+1kZGTgdFqzuCZMmIDX6+Wjjz4iNTWV1atXExsbe9R11SWFq0Yi2gE5pRq5EhEREZEjc8011/DYY4+xcOFCBg8eDFhTAi+88EISEhJISEjgzjvvDLa/+eab+eyzz3jzzTfrJFzNnz+fX3/9lY0bN5KWlgbAzJkz6dGjBz/++CPHH388W7Zs4a9//Stdu3YFoFOnTsHjt2zZwgUXXECPHj2Ij4+nY8eOR11TXVO4aiSiy3tK4UpEREQkzDijrRGkUH12DXXt2pVBgwbx0ksvMXjwYNavX8/XX3/NAw88AIDf7+ehhx7izTffZPv27ZSWluL1eomOrvlnHMqqVatIS0sLBiuA7t27k5iYyKpVqzj++OOZOHEi1113Ha+88gpDhgzh4osvpkOHDgDccsst3HDDDXzyyScMHz6ciy66KOyuE9M1V41ElF3XXImIiIiEJcOwpuaFYiuf3ldT1157Le+88w75+fm8/PLLdOjQgdNOOw2Axx57jKeeeoq77rqLr776ioyMDIYPH05paWl9/NSqNWXKFFauXMlZZ53Fl19+Sffu3ZkzZw4A1113HevXr+fSSy/l119/pX///jzzzDMNVltNKFw1EhUjV1otUERERESO1CWXXILNZmPWrFnMnDmTa665Jnj91TfffMO5557LFVdcQZ8+fWjfvj1r166ts8/u1q0bW7duZevWrcF9v/32Gzk5OXTv3j24r3Pnztx+++18/vnnXHDBBbz88svB99LS0rjmmmt45513uOOOO3jxxRfrrL66oGmBjUSUpgWKiIiIyFGKjY3l0ksvZdKkSeTl5TF+/Pjge506deLtt9/m22+/pUmTJjzxxBPs3LmzUvCpCb/fT0ZGRqV9brebIUOG0KtXL8aOHcu0adMoKyvjxhtv5LTTTqN///4UFxfz17/+lYsuuoh27dqxbds2fvzxRy688EIAbrvtNoYPH07Lli3x+Xx89dVXdOvW7Wh/JHVK4aqRiHaUTwssUrgSERERkSN37bXX8r//+7+MGjWKli33r3I4efJkNmzYwPDhw4mOjub666/nvPPOIzc3t1bnLygooG/fvpX2dejQgfXr1/Pee+9x8803c+qpp2Kz2RgxYkRwap/dbic7O5urrrqKnTt30qxZMy644AKmTp0KWKHt5ptvZtu2bcTHxzNixAiefPLJo/xp1C2Fq0ZCC1qIiIiISF0YOHAgZjX3x0pKSmLu3LmHPLZiyfSDGT9+fKXRsD9q06YN7733XrXvuVyuQ95X65lnniEQCJCXl0d8fDw2W/hd4RR+FUm1KsJVTnHDXVAoIiIiIiI1p3DVSETbrcfc4rLQFiIiIiIiItVSuGokosqvudJqgSIiIiIi4UnhqpHQNVciIiIiIuFN4aqRqAhXBd4yyvyB0BYjIiIicoyrbkEIabzqqj8VrhqJKPv+53kluu5KREREJBScTicARUVFIa5E6lJpqbVonN1uP0zLQwvpUuyLFi3iscceY9myZWRmZjJnzhzOO++8g7Z/9913mT59OhkZGXi9Xnr06MGUKVMYPnx4pXbPPvssjz32GFlZWfTp04dnnnmGE044oZ6/Tf2y2yDGZaew1E9usY+kGFeoSxIRERE55tjtdhITE9m1axcA0dHRGIYR4qqOHYFAgNLSUkpKSupsKfZAIMDu3buJjo7G4Ti6eBTScFVYWEifPn245ppruOCCCw7bftGiRQwdOpSHHnqIxMREXn75ZUaPHs2SJUuCNyp74403mDhxIs8//zwDBgxg2rRpDB8+nDVr1pCSklLfX6leJUQ5KSz1k1NUCsSEuhwRERGRY1Lz5s0BggFLGo5pmhQXFxMVFVWnodZms9GmTZujPmdIw9XIkSMZOXJkjdtPmzat0uuHHnqI9957jw8++CAYrp544gn+3//7f1x99dUAPP/883z00Ue89NJL3H333XVWeyjERznZkVuiRS1EREREQsgwDFq0aEFKSgo+n34va0g+n49FixZx6qmnBqdo1gWXy1UnI2EhDVdHKxAIkJ+fT1JSEmDNlVy2bBmTJk0KtrHZbAwZMoTvvvvuoOfxer14vd7g67y8PMDqvHD4C1NRQ7zbmgO6t6AkLOqSo1PRh+rLyKJ+jVzq28ikfo1cDdW3R3uNjtROIBCgrKwMu91epz97v9+P3++v9r3a/Blq1OHqX//6FwUFBVxyySUA7NmzB7/fT2pqaqV2qamprF69+qDnefjhh5k6dWqV/Z9//jnR0dF1W/RRKMnfC9j4dmkG9m0/h7ocqSPz5s0LdQlSD9SvkUt9G5nUr5FLfRuZGrJfa7N4SaMNV7NmzWLq1Km89957R30t1aRJk5g4cWLwdV5eHmlpaQwbNoz4+PijLfWo+Xw+5s2bR8c2rfhlbyZp7bswanD7UJclR6miX4cOHVqnw9oSWurXyKW+jUzq18ilvo1MoejXilltNdEow9Xrr7/Oddddx1tvvcWQIUOC+5s1a4bdbmfnzp2V2u/cuTN44WF13G43bre7yn6n0xlWfxmblK8QWFDqD6u65OiE258zqRvq18ilvo1M6tfIpb6NTA3Zr7X5nEZ3n6vZs2dz9dVXM3v2bM4666xK77lcLvr168f8+fOD+wKBAPPnz2fgwIENXWqdi/dYHasFLUREREREwk9IR64KCgpYv3598PXGjRvJyMggKSmJNm3aMGnSJLZv387MmTMBayrguHHjeOqppxgwYABZWVkAREVFkZCQAMDEiRMZN24c/fv354QTTmDatGkUFhYGVw9szBKiFa5ERERERMJVSMPV0qVLOf3004OvK657GjduHDNmzCAzM5MtW7YE33/hhRcoKytjwoQJTJgwIbi/oj3ApZdeyu7du7nvvvvIysriuOOO49NPP62yyEVjlOCxuiunSOFKRERERCTchDRcDR48GNM0D/p+RWCqsGDBghqd96abbuKmm246isrCU0KURq5ERERERMJVo7vm6lgWXx6u8hSuRERERETCjsJVI5IQZQ00auRKRERERCT8KFw1IhWrBRaW+vH5AyGuRkREREREDqRw1YjEe/ZfIqepgSIiIiIi4UXhqhFx2G3EuTU1UEREREQkHClcNTIVi1rkKFyJiIiIiIQVhatGRsuxi4iIiIiEJ4WrRiZBy7GLiIiIiIQlhatGRiNXIiIiIiLhSeGqkQmGqyKFKxERERGRcKJw1cgkRmvkSkREREQkHClcNTLxmhYoIiIiIhKWFK4amQQtxS4iIiIiEpYUrhoZLWghIiIiIhKeFK4aGS3FLiIiIiISnhSuGhmNXImIiIiIhCeFq0ZG4UpEREREJDwpXDUyFUuxF5X68fkDIa5GREREREQqKFw1MnEeZ/C5Rq9ERERERMKHwlUjY7cZxHkcgMKViIiIiEg4UbhqhIL3uipSuBIRERERCRcKV42QlmMXEREREQk/CleNkFYMFBEREREJPwpXjZDClYiIiIhI+FG4aoQqlmNXuBIRERERCR8KV41QvEauRERERETCjsJVI6RpgSIiIiIi4UfhqhHSUuwiIiIiIuFH4aoR0lLsIiIiIiLhR+GqEdK0QBERERGR8KNw1QgpXImIiIiIhB+Fq0YoMcoFKFyJiIiIiIQTR6gLkMNY+xm2tZ+TmhsHjAL2j1wV+/yUlgVwOZSRRURERERCTb+Vh7uNi7Av/S/J+SuDu+I8DgzDeq7RKxERERGR8KBwFe6adQYgtiQzuMtmM4hzW4OOClciIiIiIuFB4SrclYerOG9mpd0J0RWLWpQ2eEkiIiIiIlKVwlW4Kw9X0aV7wFcU3K0VA0VEREREwovCVbiLaYoZlWQ9z/49uFvhSkREREQkvChcNQJm004AGNnrgvuCy7EXKVyJiIiIiIQDhavGoGlHoHK4Sol3A7B5b1G1h4iIiIiISMMKabhatGgRo0ePpmXLlhiGwdy5cw/ZPjMzk8svv5zOnTtjs9m47bbbqm03bdo0unTpQlRUFGlpadx+++2UlJTU/RdoIGazqiNXvVsnALB8a04oShIRERERkT8IabgqLCykT58+PPvsszVq7/V6SU5OZvLkyfTp06faNrNmzeLuu+/m/vvvZ9WqVfzv//4vb7zxBvfcc09dlt6ggtMC96wP7uvTOhGAFTvy8PkDoShLREREREQO4Ajlh48cOZKRI0fWuH16ejpPPfUUAC+99FK1bb799ltOOukkLr/88uAxY8aMYcmSJQc9r9frxev1Bl/n5eUB4PP58PlCf01TWUI7q6P2rsdX6gXDRqt4F/EeB3klZazcto8eLeNDXabUUsWfrXD4MyZ1R/0audS3kUn9GrnUt5EpFP1am88KabiqD4MGDeLVV1/lhx9+4IQTTmDDhg18/PHHXHnllQc95uGHH2bq1KlV9n/++edER0fXZ7k1Yph+zjIc2MtK+GruKxS7kwFo6baRV2LjtU+/4eTmZoirlCM1b968UJcg9UD9GrnUt5FJ/Rq51LeRqSH7taio5mscRFy4uvzyy9mzZw8nn3wypmlSVlbGX/7yl0NOC5w0aRITJ04Mvs7LyyMtLY1hw4YRHx/6ESGfz0fh6lTiS7ZzRu/WmB3OBGCNaz2rF24g0CSNUaN6hrhKqS2fz8e8efMYOnQoTqcz1OVIHVG/Ri71bWRSv0Yu9W1kCkW/Vsxqq4mIC1cLFizgoYce4rnnnmPAgAGsX7+eW2+9lQcffJB777232mPcbjdut7vKfqfTGTZ/GXM8LYkv2Y5j3wZwjgDgT22TgA38uj0vbOqU2gunP2dSd9SvkUt9G5nUr5FLfRuZGrJfa/M5EReu7r33Xq688kquu+46AHr16kVhYSHXX389f/vb37DZGufq8/nuFtaTPWuD+3qnWSsGrttVQIG3jFh3xHWniIiIiEij0TiTxiEUFRVVCVB2ux0A02y81yUVeCrC1QH3uorz0CoxCtOEX7flhqgyERERERGBEI9cFRQUsH79/uXFN27cSEZGBklJSbRp04ZJkyaxfft2Zs6cGWyTkZERPHb37t1kZGTgcrno3r07AKNHj+aJJ56gb9++wWmB9957L6NHjw6GrMZof7haW2l/n7QEtucUk7E1h4EdmoagMhERERERgRCHq6VLl3L66acHX1csKjFu3DhmzJhBZmYmW7ZsqXRM3759g8+XLVvGrFmzaNu2LZs2bQJg8uTJGIbB5MmT2b59O8nJyYwePZp//OMf9f+F6lFBxbTAwl1QvA+imgDW/a4+/jVLNxMWEREREQmxkIarwYMHH3Kq3owZM6rsO9zUPofDwf3338/9999/tOWFlTJ7FGZcC4z8TNizHtKOB+C4tEQAlm/LCV1xIiIiIiISeddcRTKzaSfryQFTA3u2SsBmQGZuCTvzSkJUmYiIiIiIKFw1ItWFqxi3g86pcQCaGigiIiIiEkIKV41JMFytq7S7T+tEQFMDRURERERCSeGqETGbVR25AuhTcd3VVi3HLiIiIiISKgpXjUhwWuC+jeD3Bff3Kb+Z8PJtOQQCjfdeXiIiIiIijZnCVWMS1wKcMRAog70bg7u7pMbhcdrILyljY3ZhCAsUERERETl2KVw1JoYB1UwNdNht9GpVPnqlRS1EREREREJC4aqxadbZevzjdVfli1pkKFyJiIiIiISEwlVjEwxXf1gxMLioRU7D1iMiIiIiIsARhKvi4mKKioqCrzdv3sy0adP4/PPP67QwOYiDrBh4XHm4+i0zD2+Zv4GLEhERERGRWoerc889l5kzZwKQk5PDgAEDePzxxzn33HOZPn16nRcof3DgyJW5f2XA1k2iSIpx4fObrMrMD1FxIiIiIiLHrlqHq59++olTTjkFgLfffpvU1FQ2b97MzJkzefrpp+u8QPmDpPZg2MCbCwW7grsNw6BPay1qISIiIiISKrUOV0VFRcTFxQHw+eefc8EFF2Cz2TjxxBPZvHlznRcof+D0QGJb63mVqYFNAIUrEREREZFQqHW46tixI3PnzmXr1q189tlnDBs2DIBdu3YRHx9f5wVKNQ62YmD5zYQztuU0cEEiIiIiIlLrcHXfffdx5513kp6ezoABAxg4cCBgjWL17du3zguUagQXtfjDioHly7Fv2F1IbrGvgYsSERERETm21TpcXXTRRWzZsoWlS5fy6aefBvefeeaZPPnkk3VanBzEQVYMbBLjom3TaAB+0eiViIiIiEiDOqL7XDVv3py+fftis9nIy8tj7ty5xMXF0bVr17quT6pzkHtdAfRra113tXDN7oasSERERETkmFfrcHXJJZfw73//G7DuedW/f38uueQSevfuzTvvvFPnBUo1KsJV7hYoLar01vAezQH4ZEUW5gFLtYuIiIiISP2qdbhatGhRcCn2OXPmYJomOTk5PP300/z973+v8wKlGtFNIcoaoSJ7faW3TuucTIzLzvacYjK0aqCIiIiISIOpdbjKzc0lKSkJgE8//ZQLL7yQ6OhozjrrLNatqzpNTeqBYRx0xUCP084Z3VIBa/RKREREREQaRq3DVVpaGt999x2FhYV8+umnwaXY9+3bh8fjqfMC5SCSy69v276syltn9bKmBn70S6amBoqIiIiINJBah6vbbruNsWPH0rp1a1q2bMngwYMBa7pgr1696ro+OZiOQ6zHNZ/AHwLU4C4pRJdPDfxlW24IihMREREROfbUOlzdeOONfPfdd7z00kssXrwYm806Rfv27XXNVUPqcAbYXbBvY7VTA0/vmgLAxysyQ1GdiIiIiMgx54iWYu/fvz/nn38+MTExwWlnZ511FieddFKdFieH4I6Fdqdaz9d8XOXts3q1AODjXzU1UERERESkIRxRuJo5cya9evUiKiqKqKgoevfuzSuvvFLXtcnhdB5hPa75tMpbp3dJIcppZ+veYlZsz2vgwkREREREjj21DldPPPEEN9xwA6NGjeLNN9/kzTffZMSIEfzlL3/hySefrI8a5WC6jLQety6Bwj2V3opy2Tm9azKgqYEiIiIiIg2h1uHqmWeeYfr06TzyyCOcc845nHPOOTz66KM899xzPP300/VRoxxMQmto3gswYd3nVd4epamBIiIiIiINptbhKjMzk0GDBlXZP2jQIDIzNULS4LqMsh6rue7q9C4peJw2NmcXsXKHpgaKiIiIiNSnWoerjh078uabb1bZ/8Ybb9CpU6c6KUpqoeK6q/Vfgq+k0lsxbgeDO1urBn6iqYEiIiIiIvXKUdsDpk6dyqWXXsqiRYuCqwN+8803zJ8/v9rQJfWsxXEQ1wLyM2HTYug0pNLbo3q34NOVWXz8axZ3DuuCYRihqVNEREREJMLVeuTqwgsvZMmSJTRr1oy5c+cyd+5cmjVrxg8//MD5559fHzXKodhs0Hm49byaqYFndE3B7bCxcU8hqzLzG7g4EREREZFjxxEtxd6vXz9effVVli1bxrJly3j11Vdp1aoVDz30UF3XJzVRcd3V2k/hDwtXxLodnNbZWjVQUwNFREREROrPEYWr6mRmZnLvvffW1emkNtqdCo4oyNsOWb9Uefus3taqgR9p1UARERERkXpTZ+FKQsgZBR3OsJ5Xc0PhM7qm4HLY2LBbUwNFREREROqLwlWkqLihcDXXXcV5nAztlgrAfxb93pBViYiIiIgcMxSuIkXn4YABmRmQt6PK2zee3gGAD5bvYP2ugoatTURERETkGFDjpdgnTpx4yPd379591MXIUYhNgdb9YduP1sIW/a+p9HaPlgkM657K57/t5N9frmPaZX1DVKiIiIiISGSqcbj6+eefD9vm1FNPPapi5Ch1HmGFqzVVwxXALWd24vPfdvL+8h3cfGYnOiTHhqBIEREREZHIVONw9dVXX9VnHVIXuoyCLx+EDQugtBBcMZXe7tkqgSHdUvli1U7+/eV6nrz0uJCUKSIiIiISiUJ6zdWiRYsYPXo0LVu2xDAM5s6de8j2mZmZXH755XTu3BmbzcZtt91WbbucnBwmTJhAixYtcLvddO7cmY8/rrrQQ8RJ6QaJbcDvhfVfVNvktiGdAHgvYzsbduvaKxERERGRuhLScFVYWEifPn149tlna9Te6/WSnJzM5MmT6dOnT7VtSktLGTp0KJs2beLtt99mzZo1vPjii7Rq1aouSw9PhgE9LrCeL3252ibW6FUKARP+/eX6BixORERERCSy1XhaYH0YOXIkI0eOrHH79PR0nnrqKQBeeumlatu89NJL7N27l2+//Ran0xk87lC8Xi9erzf4Oi8vDwCfz4fP56txffWlooYa1XLcVTi+eQpjw1f4sn6Dpp2qNJlwWnu+WLWLuRnb+cup6bRrFlPNiaS+1apfpdFQv0Yu9W1kUr9GLvVtZApFv9bmswzTNM16rKXGDMNgzpw5nHfeeTVqP3jwYI477jimTZtWaf+oUaNISkoiOjqa9957j+TkZC6//HLuuusu7HZ7teeaMmUKU6dOrbJ/1qxZREdH1/arhNwJvz9Ji7yf+T15GCtaX1FtmxdW21i5z8bxyQGu6Bho4ApFRERERBqHoqIiLr/8cnJzc4mPjz9k25COXNWHDRs28OWXXzJ27Fg+/vhj1q9fz4033ojP5+P++++v9phJkyZVWmo+Ly+PtLQ0hg0bdtgfYEPw+XzMmzePoUOHBkfjDsXYEAWzL6Z93ne0OfM/4I6r0iatTy4XPL+EZXtsPDT2FNKbavSqodW2X6VxUL9GLvVtZFK/Ri71bWQKRb9WzGqriRqHq0cffZSbb76ZqKgoAL755hv69++P2+0GID8/n7vuuovnnnuuluXWrUAgQEpKCi+88AJ2u51+/fqxfft2HnvssYOGK7fbHfweB3I6nWH1l7HG9XQaAk07YmSvx7nqXTj+uipN/pTejDO6pvDl6l1MX7SJJy45ru4LlhoJtz9nUjfUr5FLfRuZ1K+RS30bmRqyX2vzOTVe0GLSpEnk5+cHX48cOZLt27cHXxcVFfGf//ynxh9cX1q0aEHnzp0rTQHs1q0bWVlZlJaWhrCyBmSzwfH/z3r+w4twkJmft55pXY819+ftrM6qeSIXEREREZGqahyu/nhpVphcqlXFSSedxPr16wkE9l9HtHbtWlq0aIHL5QphZQ3suDHgjIHdq2HT4mqb9ElLZHiPVAIm3PZ6BiU+fwMXKSIiIiISOUK6FHtBQQEZGRlkZGQAsHHjRjIyMtiyZQtgjZZdddVVlY6paF9QUMDu3bvJyMjgt99+C75/ww03sHfvXm699VbWrl3LRx99xEMPPcSECRMa7HuFBU8C9LnMev7DCwdt9vfzetE0xsXqrHwe/3xNAxUnIiIiIhJ5Qhquli5dSt++fenbty8AEydOpG/fvtx3332AddPgiqBVoaL9smXLmDVrFn379mXUqFHB99PS0vjss8/48ccf6d27N7fccgu33nord999d8N9sXBxQvnUwNUfQe62apskx7l59KLeALz49Ua+Wb+noaoTEREREYkotVot8L///S+xsbEAlJWVMWPGDJo1awZQ6Xqsmho8ePAhpxfOmDGjyr6aTEccOHAg33//fa3riTgp3SD9FNj0tXVT4TPvrbbZmd1SGTugDa8t2cIdby7n09tOITH6GJpCKSIiIiJSB2ocrtq0acOLL74YfN28eXNeeeWVKm0kzJzw/6xwtWwGnPY/4Ki6KiLA387qxne/Z7NhTyF/m7OCf1/eF8MwGrZWEREREZFGrMbhatOmTfVYhtSbLmdBfCvI2w6/vQe9L6m2WbTLwbTLjuOC577lo18zOfPnFC74U+sGLlZEREREpPEK6TVX0gDsDuh/tfX8EAtbAPRunchtQ6zl2e97byVb9xbVd3UiIiIiIhGjxuHqu+++48MPP6y0b+bMmbRr146UlBSuv/56vF5vnRcodeBP48Hugm0/wsZFh2x6w+CO9G/bhAJvGRPfzMDnDxyyvYiIiIiIWGocrh544AFWrlwZfP3rr79y7bXXMmTIEO6++24++OADHn744XopUo5SbDIcN9Z6/u6foTD7oE3tNoMnLz2OWLeDHzft4+53fg3be5qJiIiIiISTGoerjIwMzjzzzODr119/nQEDBvDiiy8yceJEnn76ad588816KVLqwLC/Q7POkL8D5v4FAgcfkUpLiubpMcdhtxm889M2HvlU978SERERETmcGoerffv2kZqaGny9cOFCRo4cGXx9/PHHs3Xr1rqtTuqOOxYuehkcHlj3OXz3zCGbn9E1lYcv6AXA8wt/56XFGxuiShERERGRRqvG4So1NZWNG61fsEtLS/npp5848cQTg+/n5+fjdDrrvkKpO817woh/Ws+/mApbfzhk80v6p/HX4V0AeODD33h/+Y76rlBEREREpNGqcbgaNWoUd999N19//TWTJk0iOjqaU045Jfj+L7/8QocOHeqlSKlD/cZDzwvB9MPb10DR3kM2v3FwB8YPSgfgjjczWLxuT/3XKCIiIiLSCNU4XD344IM4HA5OO+00XnzxRV588UVcLlfw/Zdeeolhw4bVS5FShwwDzp4GSe0hdyu8NwEOsWCFYRjcd3Z3zurdAp/f5M+vLGXF9tyGq1dEREREpJGo8U2EmzVrxqJFi8jNzSU2Nha73V7p/bfeeovY2Ng6L1DqgSceLp4B/x0Caz6G75+DgRMO2txmM3jikj7sLSjluw3ZjHvpB2ZcfQK9Wic0XM0iIiIiImGu1jcRTkhIqBKsAJKSkiqNZEmYa9EHhj9kPZ93H6z59JDN3Q47/7mqH71aJZBdWMplL3zH1+t2N0ChIiIiIiKNQ41Hrq655poatXvppZeOuBhpYMdfZy1q8eub8MYV1mhWt7MP2jze42TW/xvAX15dxjfrs7n65R/518V9OK9vq4arWUREREQkTNV45GrGjBl89dVX5OTksG/fvoNu0ogYBpz3HPS4AAI+eGscrJx7yEPiPE5eGn88o/u0pCxgctsbGby4aEPD1CsiIiIiEsZqPHJ1ww03MHv2bDZu3MjVV1/NFVdcQVJSUn3WJg3B7oQLXgSbwxrBevsaayXBnhce9BC3w85Tlx5Hcqybl77ZyD8+XsXOvBLuGdUNm81owOJFRERERMJHjUeunn32WTIzM/mf//kfPvjgA9LS0rjkkkv47LPPMA+x2pw0AnYHnP889LncClbvXAe/vHnIQ2w2g3vP7sY9o7oC8N/FG7lp9k9kF3gbomIRERERkbBTqwUt3G43Y8aMYd68efz222/06NGDG2+8kfT0dAoKCuqrRmkINjuc+yz0vRLMALx7PWTMOuQhhmFw/akdePLSPjhsBh//msWQJxby1tKtCtwiIiIicsyp9WqBwQNtNgzDwDRN/H5/XdYkoWKzweinod/VgAlzb4QV7x72sPP7tubtGwbRtXkc+4p8/PXtX7jshe/5fbcCt4iIiIgcO2oVrrxeL7Nnz2bo0KF07tyZX3/9lX//+99s2bJF97iKFDYbnP0k9L8GMK0RrN+/POxhx6Ul8sHNJzNpZFc8ThtLNu5l5LSveXLeWrxlCt8iIiIiEvlqHK5uvPFGWrRowT//+U/OPvtstm7dyltvvcWoUaOw2Y54AEzCkWHAqH/tX0Xw9Stg27LDHua02/jzaR2Yd/tpDO6STKk/wFPz1zFy2td8s35PAxQuIiIiIhI6NV4t8Pnnn6dNmza0b9+ehQsXsnDhwmrbvfvu4aeRSSNgs8P5/4HifbDhK3jtQrjmM0jucthD05KieXn88Xz8axZTPljJhj2FjP3vEs7p05LJZ3UjJd7TAF9ARERERKRh1ThcXXXVVRiGltk+pjhccOmrMPMc2L4MXjnfCliJaYc91DAMzurdglM6N+OJz9cy87tNvL98B1+t3sUdwzpzxYltcdg14ikiIiIikaPG4WrGjBn1WIaELXcsXP4WvDwC9qzdH7Bimtbo8HiPkynn9OCifq3529wVLN+aw5QPfuOtZdt48Lye/KlNk3r+AiIiIiIiDUNDB3J4MU3hyjkQ3xqy18H/nQ1rP4daLLfes1UC794wiH+c35N4j4OVO/K44LlvufX1n9mRU1yPxYuIiIiINAyFK6mZhNZWwIpuCrt+g1kXw39OhZVzIRCo0SnsNoOxA9ry5Z2DubhfawwD3svYwRmPL+CJeWspKi2r3+8gIiIiIlKPFK6k5pI7ww3fwaCbwRkDWb/AW+PguRNh+evgr1k4ahbr5rGL+/DBTSdzQrskSnwBnp6/jtP/tYB3f9pGIKAbEIuIiIhI46NwJbUTlwrD/g63r4BT/wc8CbBnDcz5M0wfBFm/1vhUPVsl8Mb1JzJ97J9IS4piZ56XiW8uZ9TTX/PhLzvwK2SJiIiISCOicCVHJjoJzvgb3LYCzrzfmi64Zw28eAYs+c+hr8cK+GHDQsjLxDAMRvZqwbzbT+OuEV2JdTtYnZXPTbN+Zvi0Rcz5eRtl/ppNOxQRERERCSWFKzk6nng4ZSJM+BE6jwB/KXzyPzB7DBRmV25bkgffPQdPH2ct7/78ybDzN+s0Tjs3DO7A4rtO59YzOxHvcbB+VwG3v7GcIU8s5M0ft+It8zf89xMRERERqSGFK6kbMU1hzOsw8lGwu2DtJ9Y0wQ0LYd9m+PQeeKI7fDYJcrYABhTtgRlnVZpKmBjt4vahnVl89xn8dXgXmkQ72ZRdxP+88wv9//4Fd7y5nK9W76K0TKNZIiIiIhJeanyfK5HDMgwY8GdoOwjevsa6L9bMc639ZnkYatYFTrzBGuV6/XLY8RP832i4ci60PC54qniPkwmnd2T8oHReW7KZlxZvIiuvhHd+2sY7P20j3uNgeI/mnN2nJYM6NMWpGxKLiIiISIgpXEnda94Lrl8An06Cn/7Puv6q/ekw8CbocAbYyoPQVXPh1Qth24/WNMEr50CrfpVOFeN2cP2pHbju5PYs27KPD5fv4OMVWezO9/LWsm28tWwbSTEuRvVqzjl9WtG/bRNsNqPBv7KIiIiIiMKV1A9XDJzzNPS90rouK7lL1TaeBLjiXXjtYtj6Pcw8z3qddnyVpjabwfHpSRyfnsR9o3vw46a9fPRLJp+syGRPQSmvfr+FV7/fQssED2f3acno3i3p0TJeQUtEREREGozCldSvaoJSJZ54uOIdmHUJbP4GXjkfLnsN2p920EPsNoMT2zflxPZNuX90d779PZv3l+/gsxVZ7Mgt4YVFG3hh0QZi3Q56tUqgd1oCfVon0ictkZYJHgxDgUtERERE6p7ClYSeOxbGvgWzLoVNX1tTBPtfA0OmWuHrEBx2G6d2TubUzsn8/byeLFizm/eXb+er1bsp8Jbx3YZsvtuwf9XCxGgnTaJdxLod1uZxEOd2kBDtJL1pDO2aWVvLxCjsGvUSERERkVpQuJLw4IqBy9+ET++Cn2bC0pdgzadw1uPQdVSNTuFx2hnRszkjejanzB9g3a4Clm/NYfm2XH7ZlsPqrHxyinzkFPkOX47DRnrTaDqnxjG0eypndE0hzuM82m8pIiIiIhFM4UrChysaznkGel0MH9wKezfA62Ogx/nWEu+xKTU+lcNuo1uLeLq1iOeyE6x9JT4/G/cUkl9SRoHXV/5YRkFJGdmFpWzcU8imPYVszi6itCzA2p0FrN1ZwIe/ZOKy2zilUzNG9GzO0O6pJEa76umHICIiIiKNlcKVhJ92p8IN38KCf8K3z8DKOfD7V9B5OCS2hSbp0KT8Ma4F2Ow1Oq3Haadbi/JphiW5sGkx7Fhg3YurIAvOegJ6XYQ/YLIjp5jfdxewdNM+PlmRye+7C5m/ehfzV+/CYTP4U5smtGsWQ5um0bRJsra2TaNJiHLqmi4RERGRY5TClYQnZxQMnQo9L4D3b4bM5fDLG1XbOTzQ5zIYfA/EpR76nLvXWufYsMC6v5b5hxsRv3Mt7FmHffDdpCVFk5YUzeAuKdw5vAvrdubz8a9ZfLIik9VZ+fywaS8/bNpb5SOaxboZ0D6JE9slcWL7pnRMiVXYEhERETlGhDRcLVq0iMcee4xly5aRmZnJnDlzOO+88w7aPjMzkzvuuIOlS5eyfv16brnlFqZNm3bQ9q+//jpjxozh3HPPZe7cuXVevzSAFn3gui9h3WfWTYn3bYJ9myFnM+RsgbISWDYDfnkLTrrFupeWO7byObb+AIunwZqPKu9v2hHanQbtB8PWJfDdv2HhPyF7HZz7rBXwynVKjePW1DhuHdKJjXsKydi6jy3ZxWzeW8jWvUVszi5iV76XPQVePvolk49+ybQ+IsbFCe2SGNAuiePbJdG1ebwWyhARERGJUCENV4WFhfTp04drrrmGCy644LDtvV4vycnJTJ48mSeffPKQbTdt2sSdd97JKaecUlflSqjYHdD1LOCsyvsDftjyHcy7D7YvgwUPWwthnH4PHDcW1s+Hb6ZZbSp0HgndRltLvSe03r+/+znWvbg+vB1WvGMFuMtmVTsaVrGi4B8VlZaxYnse32/IZsnGbJZt3kd2YSmfrMjikxVZAMR5HPRv24Tj2yXRLy2BUn8d/HxEREREJCyENFyNHDmSkSNH1rh9eno6Tz31FAAvvfTSQdv5/X7Gjh3L1KlT+frrr8nJyTnaUiUc2eyQfjJcN9+6Lmv+VGtk64Nb4bO/QWlBeTsn9LkUBt0KyZ0Pfr4/XQVN2sGbV8L2pfDiGXDxyxDdFIr2QlE2FJc/+kvBHV++xYEnnmh3PCd44IT0bEjdS1nPPezMyiR79w7WFETxSk5vfilpzldrdvPVmt3lH+rgoRVf0TIxytoSPLRMjKJ5gofkODep8R5S4tzEuh31O72wYDdsXAixqdaIXlxz0HRGERERkVqJyGuuHnjgAVJSUrj22mv5+uuvD9ve6/Xi9XqDr/Py8gDw+Xz4fIdftru+VdQQDrWErS6jocMwbD+9jG3x4xjF+zBdsQT+NJ7ACX+2Fr4AONzPsPWJMP4zHG9ejpG9Hv536BGX5ABalW+9gYsNKG7emZWJp/N+2Ql8uCOevUU+9pVvK3fkHfRcUU4byXFunHYbgYBJWcAkYJoY/lJ6BNbiNsrw29wE7C78Ng9+uwucMXRs155zjmtB59S46k/szcf2/bPYlkzH8BUGd5vOGEhqj5nUHjOlO4E/jbdCphyW/r5GLvVtZFK/Ri71bWQKRb/W5rMM0zTNeqylxgzDOOw1VwcaPHgwxx13XJVrrhYvXsxll11GRkYGzZo1Y/z48eTk5BzymqspU6YwderUKvtnzZpFdHR0Lb6FhANnWSHNClaxO7YbZY6q0/dqeo6+m1+gRd7PlNk8eB2x+OyxeB1xlDpiCRgOnIESHP4inP5iHP5inP4iAEodsdZmj6PUEUepI4b44q2k5K/AZu6fB5jraU22Jx1vwEZJwE5xwEZxwEaR387WQDO+93dlma8Nhf7K/w/EIEA/Yy3n2b9hlH0JSUbBQb/H1kAynwf6s8zZD2ezTvRNNmjiBluglPQ9X9I5633cfuv4fHcLDAJEe3djo/JiH157LCtbjWFr0ska0RIREZFjSlFREZdffjm5ubnEx8cfsm1EjVzl5+dz5ZVX8uKLL9KsWbMaHzdp0iQmTpwYfJ2Xl0daWhrDhg077A+wIfh8PubNm8fQoUNxOnUj24ZzMb5AGdgcuAAXUJOoFlW+/ZG/OIfA2k+wrXoPY+NCEkq2kVCy7aDnuREwo2Pwt+hLXnI/dsZ2I2Z3BimbP8RTuP84n6cpvqgUDH8JRpkXm78Em9+LvayYNNturrV9wrXmJ2TvimN+5p/Yl9iJ0cXv09S/C4BMRxpzmlxNRuwppMZ7aBlnp6MzmzRzB6m+bSSsfRv37lX8acuLHGf8hn/kv6Bpp1r8HI8t+vsaudS3kUn9GrnUt5EpFP1aMautJiIqXP3+++9s2rSJ0aNHB/cFAtb/gXc4HKxZs4YOHTpUOc7tduN2u6vsdzqdYfWXMdzqOTbU4c/bmQz9r7K24n2UrfqYNUsX0LVzJ+wG1gIdpt+6nmvnb7DtB4ySXBxbFpO0ZTFJB57LFWctzNH7YpztTsNZ3b2+Sgvh968oXfk+5ppPaerL5RLHQihYCMAOM4lpZRfyTsmp+AvswO4/nCAO6IbHdg93xH/BOO/ruDZ/Ay+cSl7/W3ANvoOteQHr5svZhWzdlUPmnmz2lpi4ouNJiHIS73GSEGVtSTFOUuM9NE/w0DzeQ9NY9yFXTvT5AxR6y8gv9lGStxtf9mYCOVtIjHLQMiUVW1QCeBLAE289Oqr+Ha5W1grr+rKuZ1v3S6sn+vsaudS3kUn9GrnUt5GpIfu1Np8TUeGqa9eu/Prrr5X2TZ48mfz8fJ566inS0tJCVJnIH0Q1wex1Ceu3xtL5pFHYq/tLGwjA7tWw9XvYsgQyM6wFN3pfbK166DrMlFVXDHQ7G1e3s8FfBlu+pWD5exRtyWBb8qmsbXsZx9mjOA5rpp/PHyArt4TM3BK25xSTmVtMVm4JJX47/8gZzv8ZfXnQ8TKns5zEHx5nz5IXicXJiZRwBiW4DGvKY5lpY/HeXrzvH8hngf4UUH2ddptBSpybGLeD0rIAhq+YNP9m2pVtpKO5mTSyaGXsobWxmxjDW+05KklqDx2HQqeh1kInByylT+Ee+PUtyJgFWb9Y+zYthjGzD39eERERkRoKabgqKChg/fr1wdcbN24kIyODpKQk2rRpw6RJk9i+fTszZ84MtsnIyAgeu3v3bjIyMnC5XHTv3h2Px0PPnj0rfUZiYiJAlf0iYc9mg9Tu1tb/mqM7l90B7U4ltt2pxAIpwJ9qcFggYJKZV8LarHzW7Mzng8zj+G7rp1xX8DwpRk61xziMAIPtyxlsX06Z4WJ94iCWxZ1BBp0pycsmkL8TZ0k2SeTRrDCXtkVZdDW20s7IwmaYYKu+lmyjCbtsKRSVGUSbhcQZxcRTRCzF1nF7N8AP/4Ef/kMJLpbSnSVmD050/s6JZT9ixwp/pmHDMAOw+RsrwNoO8oEiIiIitRTScLV06VJOP/304OuK657GjRvHjBkzyMzMZMuWLZWO6du3b/D5smXLmDVrFm3btmXTpk0NUrPIscRmM2iVGEWrxChO75pSvrcvZcUTKNiSQUxsLIYr1holq9j2bYIV78KKt3HsWUvXfQvoum8BYw888UFG18s8TfE164Y/uQdGcmfczdJxJKVDQmuaOj00xRphW7E9l4Ub97JkQzZLN2VjL8llgG01p9kyGGxfTktjLyeTwclGBpRZ5/4l0I63/afyiX8Aizy3E1WSa92YOqVrPf30RERE5FgT0nA1ePBgDrVY4YwZM6rsq+3ihtWdQ0SOjiMqntgup1b/ZrNOMPguOO1/YOcK66bMK96BnK3Wcu4xyRCbbD3GJFs3c07tAak9ccSmHPYfJafdRt82Tejbpgl/Oa0DZf4Aa3bmU1Q6DIfNYK/NoCRvLfFbFxKV+QN7PGl8EzOUxXkprMrMZ/eeQjL8HRho/w22LlG4EhERkToTUddciUgYMQxo3svahkyptyl4DruNHi0T/rD3BOh+AmCt8NgWuLz8nVWZecx/thMD+Y3A1iXY+o2r85pERETk2KSLDUSkYYTJtU2dU+NYYesGQNmm70NcjYiIiESS8PhtR0SkgdhtBt7m1nIerpzfoTA7xBWJiIhIpFC4EpFjTnpaa9YFWlkvtv0Y2mJEREQkYihcicgxp1erBJYFOlkvtmpqoIiIiNQNhSsROeb0apXAMrMzAOaWJSGuRkRERCKFwpWIHHPaJ8fym91agt3cvgz8vhBXJCIiIpFA4UpEjjl2m0FU867sM2Ox+b2Q9UuoSxIREZEIoHAlIseknq0TD7ju6ofQFiMiIiIRQeFKRI5JvVol8FPAuu6KrbruSkRERI6ewpWIHJN6tU5gWXm4MjVyJSIiInVA4UpEjkkdkmNZ6+hEmWnDyNsOOVtDXZKIiIg0cgpXInJMstsM2rdMZqWZbu3Q1EARERE5SgpXInLMsm4mXHHdlaYGioiIyNFRuBKRY1bPSuFKI1ciIiJydBSuROSYZY1cWcuxm1m/QmlhiCsSERGRxkzhSkSOWR2SY8hxJrPdbIph+mH7T6EuSURERBoxhSsROWY57Da6t4jnp+DNhDU1UERERI6cwpWIHNN66borERERqSMKVyJyTOv5xxUDA4HQFiQiIiKNlsKViBzTerVOYJXZhiLTDSU5kL0u1CWJiIhII6VwJSLHtI7JsTicLpYHOlg7tnwf2oJERESk0VK4EpFjmsNuo1uLeH40y6cGzrsPfns/tEWJiIhIo6RwJSLHvF6tEni5bATbo7tZUwPfvBI+uFX3vRIREZFaUbgSkWNez1YJ7COev8Y/CiffDhiwbAa8MBgyfwlxdSIiItJYKFyJyDGvV6sEAH7JLCZwxv1w1VyIbQ571sJ/z4TvnoOAP7RFioiISNhTuBKRY16nlFjcDhsF3jI2ZRdC+8Fww7fQZRT4S+GzSfBkD/j8Xtj5W6jLFRERkTClcCUix7yKRS0Aft2ea+2MaQqXzYJR/wJPIuRnwrdPw/SB8PzJ8N2zkL8zdEWLiIhI2FG4EhFh/9TAHzbu3b/TMOCE/wd3roVLX4WuZ4PNCVm/wmf3wBNd4cUz4auHYMsS8JeFqHoREREJB45QFyAiEg6Gdk/lle838+bSrfy/U9qT3ixm/5sON3QbbW1Fe2Hlu7D8ddj2I2xfam0LHwF3Avb0U2hb1AyyO0NqVyugiYiIyDFB4UpEBDilUzNO7ZzMorW7+cfHq3jxqv7VN4xOguOvs7bc7fD7l/D7fPj9KyjJwbbmQ44DeH4GxKZC25Mg/SRIPwWadVbYEhERiWAKVyIigGEY3Hd2N4ZP28O833ayeN0eTu7U7NAHJbSCP11pbQE/7MjAv/Zz9v00h6bFmzAKdlqjXCvftdpHNYGU7lbISu4KyV2sLa6FQpeIiEgEULgSESnXMSWOK09sy4xvN/HAhyv5+JZTcNhreGmqzQ6t+xFI7c03+d0ZNewMnDuXw6ZvYNPX1hTC4n2w+RtrO5ArDpqkQ5O2kNSu/Hk6NGkHiW3A7qzjbyoiIiL1QeFKROQAtw3pxNyM7azdWcDsH7Zw5cD0IzuRwwPpJ1sbd0GZF3atsu6dtXs17F5jbXs3QGk+7PzV2v7I5rACVlL7/Vt8K2t6YlTS/keH62i+toiIiNQBhSsRkQMkRru4Y2hn7n1vJY/PW8voPi1JjK6D4OJwQ8vjrO1AZaWwb9MB20brcW/5Y1mxFcD2bjj0+V2xVghL7QmpPaB5T+t5bOr+KYemaYU8b74V6GJSwB179N9NREREAIUrEZEqxpzQhle/38KanflM+2IdU87pUX8f5nBBcmdr+6NAAAqyrGCV/Xt5yPrdur9W8V5r5cLifYAJpQWw6zdrO3AALLoZuKLBW2CFqoCv8mcktIGUrtY1YCndrMeKkTFNRxQREakVhSsRkT9w2G3cN7o7Y/+7hFe+38zYAW3olBrX8IXYbBDf0trST66+TSAAJTlW0MpeDztXlG8rrddFe6ComuMcUdaoWO4Wa1v3edU27ngrZEU33T8F0ZNoLcwR1QSiEq39Ca2sUTN3CH5GIiIiYUThSkSkGid1bMbQ7qnM+20nD3z4GzOvOQEjHFf0s9nKA1ASNOsIXUbsf6+0CPassW5u7I4r32KtKYQ2uxXIdq2C3atg1+r914IV7gZM8OZZ275NNaslqokVshLbWCsglpVYI2alBfsfA35o2r58tcTyFRObdgKnp/K5KqYwGoY1pVJERKQRULgSETmIv43qxoI1u/h63R5mfLuJ8YPSwzNgHYwrGlr2Pfj70Unl9+A6qfL+gB9KcqEo2wpgRdnWVrzPGiUr3le+5VgjY7nbDti3DzKXH7quXSth1Qf7Xxs269qwQJkVqMq84Pfuf98dDzHNICa5fGtmTXcMPja1Rteim4EnHmxOa0qjzV7bn5iIiMhRCWm4WrRoEY899hjLli0jMzOTOXPmcN555x20fWZmJnfccQdLly5l/fr13HLLLUybNq1SmxdffJGZM2eyYsUKAPr168dDDz3ECSecUI/fREQiUXqzGK4/tT3PfvU7Uz/4jYVrd/PPC3rTPMFz+IMbM5t9/2hYTXnzIWcr5GyxtoIscEZZy8y7YspHzOIA05quWDFKtmuVFdjyMw9x7vIRtMMt6lGFUR6ynFbQdMeDJ8EKYJ6EA15XPI8/4DGucu3OmFp+toiIHItCGq4KCwvp06cP11xzDRdccMFh23u9XpKTk5k8eTJPPvlktW0WLFjAmDFjGDRoEB6Ph0ceeYRhw4axcuVKWrVqVddfQUQi3B1Du9Ak2sWjn61hwZrdDHtyIVPP7cF5x7VqXKNY9c0dB6ndre1wOg3d/9w0rWmIedvB7ramANpd1lL2Dpc1ila012oT3PZYj0V7rBG1wuz9zwNlB3yQCf5Sa/MVlk93PHIOZwzDTQeOzVMPmGYZZ02zDJRZ0yDLSsBXYl3PVlZqBVW70/pOFY8Oj3UdXZN0SGxr3d8ssa0V6ip+Jv5S8BVb58OA2BTdaFpEpBEIabgaOXIkI0eOrHH79PR0nnrqKQBeeumlatu89tprlV7/97//5Z133mH+/PlcddVVR16siByTbDaD605pz+Auydzx5nKWb8vl9jeW8+mKLP5xfi+axep6oKNilAeH2JSDt6m4nuxwTNMKJAGfdZ1ZwAd+n/VYWmSNfpXkWVMevXnWiFlJXjX786zrwyquFTP9Vqm+QjwAe3Pr4ptX5YrbH9IwK7/njreuT6tY1TGlm3WtWmzKwa9J8/usJf33rIXsdVBaaE2/jE2FuObWFpt6+GvaTNM6tuLnUTE1tGivtWplxXRQT6J1E+yK+7HFJCsQisgxJ+KvuSoqKsLn85GUdPDpLV6vF693//z+vLw8AHw+Hz6f72CHNZiKGsKhFqk76tfGpW0TD69fdzwvfL2Jfy/4nc9W7uSHjXu5+fQOXNK/NW6HDVC/hpxRfr1VXV1uZZrW9V/eAsqKcvh+4RcM7NcTh7+4/H5hBRilBWBzYDo85SNunvIROLcVzCoCnr8U/GUYvkLI3YaRsxlyNmPkbMEo3mvde+yPH48BhoHhzYNtP1rbH9u4YiEmGTO6/NozwMheD/s2YZQHw0N+RUcU2B3WDattzvJHh1WzNx9KCzH+GPZq8qNzxkCTdgTSBmB2HoHZZlBYLk6iv7ORS30bmULRr7X5LMM0zdr/i1kPDMM47DVXBxo8eDDHHXdclWuu/ujGG2/ks88+Y+XKlXg81V8nMWXKFKZOnVpl/6xZs4iOjq5RPSJy7NhWCK+ut5NZZP1f+USXydBWAU5MMSnPWCK14vAX4/HlEDAc+G1O/DYXfsOFadgxTD+x3iziSrYRX7KduOLtxJdsI9q7GxuHDk9lNjcF7hbke1pQZo/C7cvF48vBU5aL25eD3Sw75PEHMjEos3nwOWIotcdQ6ojFd8Cjq6yAGO9OYrw7ifLtrRLIfDYPu+J7k5XQl53xvfE5tHS/iDQORUVFXH755eTm5hIfH3/IthE9cvXPf/6T119/nQULFhw0WAFMmjSJiRMnBl/n5eWRlpbGsGHDDvsDbAg+n4958+YxdOhQnE7d1DNSqF8bt/FlAd76aTvTF25gZ56Xtzba+Wavhz+f0pa43SsZMVz9GmnC7e+s3zTxl+RC0R6Moj3Ba88M04+Z1BGzaSeIa06MYVDdchwB0yRQkrP/5tKBilG2MoxAGabNsX/pflcsOKPBMHACTqj2nBXKyryQswVjzxpsv8/HWPcZzsJdtMr5gVY5P1gjcq4Ya9ETu9tait/uwXR6rH3O6OBmVrQzHNY0Q5vdWmHSKH+02cpfl29Y+8zgOaKCj6Yzuvy6N7c1Sudw4wsYzPtqEUOHDT+6fg34rfoM/R+WcBFuf2elboSiXytmtdVExIarf/3rX/zzn//kiy++oHfv3ods63a7cburTlVwOp1h9Zcx3OqRuqF+bZycThh/UnsuO6Etb/y4lWe/Ws+O3BLu/3ANSW47+5plctkJbYlxR+w/s8essPo760qG+OSjOD4FOMT1bkfK6YSo7tCiO/Q637rZ9Y6fYc3HsOYTjF0r91/XdoBQXKHlBM4FzF8cGHa3tZCK3WWFPvsB0yRtduvR7rRCqK/IupavtMB6XlZindARVSnQ4Yq2gpzxhxBoGNa0U9NvBbPgY8A6tmJlywNXsDRN67q84FTTsj8s4sIfrnMzDnh9wPOKzz+wHpvT+oxKnxlv1YK5v7aKLeC3psyWea16/N5gOLfamNYjpvXcsFX+WVb8bA/W6w53ebCPOSDkx+w/xjCo6TV9lf7OHm7Clq4TbDQa8t/i2nxORP5X/9FHH+Uf//gHn332Gf379w91OSISwTxOO+MGpXPp8WnMWrKF5xasZ09BKQ9+tJqnv/ydsQPaMH5QOinxEb58u8ih2GzQup+1nXmvteJjSe4fVlgs30qLrNUdKz0Wl//C7t//i73pt0IbZuVf+s1AefgpLt8KD3heZK3i6Pda18AdwAiUBxVf4dF917Jiayvee3TnkVr4Y9CynjuAc8wA/AxVFomp9XkP9jwU6uKz6+iqoCO5uqi6n92hznP7SohLrf3nhEhIw1VBQQHr168Pvt64cSMZGRkkJSXRpk0bJk2axPbt25k5c2awTUZGRvDY3bt3k5GRgcvlont3a/nfRx55hPvuu49Zs2aRnp5OVlYWALGxscTGxjbclxORY4rHaeeak9txUd8WPPjq5/yQG8fmvUU8t+B3Xvx6A+f0acXVJ6XTvUU8Npv+z6gc42LKbwIdSuVL3vtKCvni048YcvppOA3//uX7y8ofK0JXwL//uWGzRlEqNme09WiaVoCrCHIVj8HRnD+M/Bi28mmO9v2PhmGtzlixcqW3YiXLAuu9inu3HTiqVjEKZn2x/d+vutcHjiaZBwRTv9eaInrgZ5bkWUHxwGmYwZpt+2+dULE5XJXbVYyQYVifWfHzqxhxCxxkkQDTtEbESgv2r1RZMTJY/QHV/nJ+9P/S/uG8YbFKgYS7kIarpUuXcvrppwdfV1z3NG7cOGbMmEFmZiZbtmypdEzfvn2Dz5ctW8asWbNo27YtmzZtAmD69OmUlpZy0UUXVTru/vvvZ8qUKfXzRUREykW57Jzc3OTB8SexcP1eXly0gaWb9/HOT9t456dtxHscHNemCcelJdK3TSLHtU6kSYwr1GWLHHsMwwoHbhulzniIb2FNZ5Tw5C8fVQz4ywOP+YdH+GOQ9Pl8fPnVl5xxxpk4na79Qe9go04V56v2edXzH/FoWI2EY5IL0f8YDPX/iKmlkIarwYMHc6jFCmfMmFFl3+EWN6wIWSIioWS3GQzv0ZzhPZrz85Z9/PfrjcxfvZO8kjIWrd3NorX7b2jbMSWWId1SGdYjleNaJ2pkS0Tkj+wOsCfU7hifjxJnE+uebgrO0kAi8porEZFw0rdNE54d2wSfP8CarHx+3prDz1v2kbElhw17Clm/q4D1uwp4fuHvJMe5g0FrUIemuB11dcMmERERqW8KVyIiDcRpt9GzVQI9WyVw5YltAcgpKmXx+j18vnInX63exe58L7N/2MLsH7bgcdro17YJJ7ZryoD2TemTlqCwJSIiEsYUrkREQigx2sXZvVtydu+WlJYF+H5DNp//lsW833ayM8/LN+uz+WZ9NgBuh40/tWlCv7ZN6NI8jq7N40hvFoPTrvvqiIiIhAOFKxGRMOFy2Di1czKndk7mwXN7sm5XAUs2ZPP9hr0s2ZjNnoJSvtuQzXcbsvcfY7fRPjmGrs3j6NI8ni7NY+mcGkerxCgM3a9FRESkQSlciYiEIcMw6JwaR+fUOK4cmI5pmvy+u4DvN+xlxfZcVmfls3ZnPkWlflZn5bM6Kx/YETw+1u2gc2osXZrH0SE5lvSmMbRLjiGtSTQuh0a6RERE6oPClYhII2AYBh1T4uiYEhfcFwiYbM8pZnVWPmuy8lizs4C1Wfn8vruAAm8ZP23J4actOZXOYzOgdZNo0pvF0L5ZDO2axQSft0yMwq6VCkVERI6YwpWISCNlsxmkJUWTlhTN0O77715fWhZgU3Yha7LyWZOVz8Y9hWzcU8im7EKKSv1s2VvElr1FlZaDB2uKYVpSFKnxHpJiXCTFuGgS7Qo+79UqgbZNozXdUERE5CAUrkREIozLYQtOKRzdZ/9+0zTZle/dH7bKHzfuKWTz3iJKywL8vruQ33cXHvTczeM9nNg+iQHtm3Ji+6akK2yJiIgEKVyJiBwjDMMgNd5DaryHE9s3rfSeP2CyI6eYzdlFZBd6yS4oZV9RKXsLrcfM3BJWbM8lK6+EuRk7mJthXd+VHOemZWIUSdFOmsS4SIp2WY8xLtokRdO2aTQtEjTdUEREjg0KVyIigv2AKYYHU1zq5+ct+/h+416+35BNxpYcdud72Z3vPeS5K6Ybpje1ru/qlBJLp9RYOqXGEe9x1vVXERERCRmFKxERqZEol51BHZsxqGMzAEp8fn7LzLNGuQpL2VtkjXLtKyxld76XzXuL2Lq3iFL/wacbNo/30CnVWs3Q5bDhsBs4bAYOmw2HzSDKZadFQhQtEz20ahJFsxg3No2CiYhImFK4EhGRI+Jx2vlTmyaHbHPgdMON2YVs2F3A+l0FrNtZQFZeSXD7et2eGn2my26jRaKHVolRtG0aTZukmPJHawpinEbCREQkhBSuRESk3hw43fDkTs0qvZdb7GP9rnzW7Sxge04xPr9JmT9AWcDEHzApCwTILykjM7eEHTnF7MwrodQfYHN2EZuzi/j29+wqnxfltONy2HDabbjsBs7y502incF7fbUrn56Y3jSGKJe9oX4UIiJyDFC4EhGRkEiIctKvbRL92ibVqL3PH2BnXgk7ckrYureIzXuL2JJdWP5YRHZhKcU+P8U+f7XH/7hpX5V98R4HMW4H0S47sW4H0S4HMW47zWLdtEqMolWTqOBj0ygFMREROTSFKxERaRScdhutm0TTukk0J7SrGsjyS3zkFPko9Qfw+QP4ykxK/QFKywLsyi9h054iNmXvX34+t9hHXkkZeSVlNfp8mwGxDjsvbP6OlDgPyXFuUuI8NIt1Ee124HbYcNltuBzW5nbYiXLaiXLZiS7fPE47bodNy9eLiEQohSsREYkIcR5nra65qliEo8jrp8BbRlFpGYWlfgpKytiVX8L2fcVsz7G2zBxrSmKez2DljnxWkn/EdTpsBonRzko3aa5Yxr7ihs3BmzjHuGga48Lj1KiZiEhjoHAlIiLHpCbl4aUmAgGTzJxC5nwyny7HHc++Ij+78kvYne9lT4E1HdFb5qe0zBop85Y/Fvv8FJX6KS71U+oPAFAWMNlTUMqegtIa1xrtstM01kVSjJtmB4SvWLc1rbHiMcZtJ87jJCHKQXyUk4QoJ26HgpmISENRuBIRETkMm80gJc5NWiwM7pyM01n7VQnL/AGKfH6KvP7gkvV7y2/UfOBm3bzZx95CL3sLS/H5TYpK/RTtLWbr3uJaf67HaSPe4yTW7cBpt5a7txb8sJ5HOe3EeRzlI3/WY3yUdR2ay24vn+K4f7pjnNtBQrSTxCgXLoet1vWIiEQyhSsREZEG4LDbiLdbQad5gqdGx5imSb63jL0FpWQXlpJdYAWu7EIrnBWWllHg9VPoLaOgpIwCbxn5Xh95xWXklfgwTSjxBSjxedl1mJs9H4kYl53EaBcJUVYw2z+C5iC2fBRtVK8WdEyJrfPPFhEJRwpXIiIiYcowDOI9TuI9TtKbxdTq2EDACmZ5xT5yi30UessoC5jWYh/ly96X+gMUl/rJLykjv6RigQ8f+SVllPj8eH0BvOWLgpSW+fGWBSjwlpFbbAW3wlI/haXWdWkH89yC9Tx2UR9G92l5tD8OEZGwp3AlIiISgWw2g4Ty667S6vjcgYBJXvnqjDnFPvYVlVJQUmaNoHnLKPT6KSot4+ctOfywaS83z/6ZFTty+Z/hXbHbtFKiiEQuhSsRERGpFZvNIDHaRWL0oRcE8QdMHv1sNf9ZuIH/LNzAqsx8nrmsLwnRtb9mTUSkMdCVqCIiIlIv7DaDSSO78fSYvnicNhat3c05zy5m7c4jX8peRCScKVyJiIhIvTqnT0veuWEQrRKj2JxdxHnPfsPfP/yNz1ZmkV1Q9wttiIiEiqYFioiISL3r0TKBD24+mQmv/cR3G7L57+KN/HfxRgDaN4uhf3oT/tSmCQlRTuw2a7l4u80ILh3vdtiIctrxOO24ndbzKKcdh13/n1hEwofClYiIiDSIpBgXr1x7Ah+vyOL7Ddks3bSXtTsL2LCnkA17Cnlz6bZanc8woGVCFG2bRtO2aQzpTaNp2zSa5Dg3ucU+9hb6gvcT21dYSlnApGWCh1ZNomiVGE2rJlEkx1T+Vcg0TcoCJmV+E8MAt8OGYWgRDhGpGYUrERERaTAOu41z+rTknPKl2XOKSvlpyz5+3LSPFdtz8foC+AIB/AEzuGR8WcCkxOcv3wKUlPkxTTBN2J5jLQX/7e/ZR1yT227nrqVfUOa3gtWBDIPgKJnHaSfKZSfW7SApxkWTaBdJMU4So10kxViLexR6y8gvv+dYxb3HbDaD6PJjo8u3KJcDA2vRj7KAiT8QwB8AfyCA3WbD6TBw2a0bNzvt1pYY5SQp1kXTGOvzYt2OSsHPNE1K/QFKfAHK/AHc5XUfbIXGQMCk2OensLQMry+Aw27gsNlw2g0cdhsOm4FhQJl//xL+Pn8gGDxj3NbNphVARfZTuBIREZGQSYx2cUbXVM7omlrjY0zTxFsWIK/Ex9a9RWzOLmJTdhGbswvZlF3E3kIviVEumsS4SIreH37sNoMdOcVs22cFsu37iin2+fH6DfAHDvJZUFTqp6jUX1dfuc647Dbio5z4A4FKobNKu/IpldEuOw67QXFpgKLSsjr7Tg6bUX7jaAdupxXK7LaKRwNn+dROj9OOx2nD47DjLn9umlBc6qfYZ20lPj/FpX4MA5zl4dJlt+F0WFNDWyZE0SElhvbNYmmfHEOcRytPSnhRuBIREZFGxTCM8l/U7aTEeejXNumIzmOaJjtzi/jg0y8YcsbpRLld1jVeNhsOu0HANK3QUv6Lf3F5yMovse7ttbfQR05RKXsLrc0wINbtINbjINbtJM7jIMZlJ2BCsc8fDDTFB4S1igBy4OY/4GbPpf4AvrIA3rIAOUWlZJd/VlGpn1J/gD01WBDEugl0gNxiX7Xv2wwrgFWMFh6Ky26NbFV8J4CygElu+c2qG1pqvJv0pjE47Ebwe3rLH0v9AYxSO3P3/kRqfBTJcW6S49wkRDnZW1jKrnwvO/NK2JXnZVd+CTlFPqJd9vL+s/ow3uPA47ITCI4w7h9pDATAZrP+PNoNA5sBtvIRvIBp4jetx0DAtF4fcA6ff//orM9v1ewtK79xd/lzm2FUGjGtGEF1O224HRWPVmh1l/eftzxkVzyWlgWIdjlIiHKSGO0kMcpJQrR1Y/IDR4S9Zdaf89KygPV9bGC32bAb1nWPhkE1PwPruwVDs9MeHC112o3ykeBApRHo4lI/+4qsvz/7yqfr7i0qxVdmEutxEFf+s4/3OIl1W69vOqPjYW/7EE4UrkREROSYZBgGTWNcpERB6yZROJ1VR0HiPCEorAaKS/3sLSolp6jUGhVyWL/gVowIOW02vGWB4IhQcWkZxaVW4Ih22YlxOYhx24lxOypN6zMPCAE+f4CAuT9Q2W1Gpel//oBJYal182jrBtLWL+p//CW8zG99bsUv/BXTO4t9fhw2KyhHlQeIipEtgFL//pDkKwtQ7AuwbV8Rv+8u4PfdhezO97Izz9oOzmDrmj312RX1KhxHTOtNXvW7/3xah4at4ygpXImIiIg0MlEuO61cUbRKjDpkmyiXvVbnNcpHKhx28DgPfazdZhDvsUZBQiGvxMeG3YVszi4ErMVHrGmE1qiO6fcz7+vvSO/Si71FZewu8LI730tOkY+kGBfJcW5S4z2klD8mRjsp9vkpKCkjP3jNnI+iUn+VqY4Ou4EBmFghM2BawTRgmpgmwSBqN6znNpuBzTBwHLgSZnDapA23c/8IlNthPZrlo4MVo6YlB0yd9JYF8Pr8lJTtD60VQdXtsEK2u3wqZVGpn5wiHznFpeQWWSOMeSU+HDZbcMSpIpy7yj+3Ihz7TRO/33oMfnfb/mvyMLA+31c5NPv8ARx2G05bxZ8n67nHaS+fpmtN1624btFpt1FQcb1i+bWK+SU+8r1lxEc1rrjSuKoVEREREQHiPU6OS0vkuLTEat/3+XxkNjEZ1b91taOSIvVBN4cQERERERGpAwpXIiIiIiIidUDhSkREREREpA4oXImIiIiIiNQBhSsREREREZE6oHAlIiIiIiJSBxSuRERERERE6kBIw9WiRYsYPXo0LVu2xDAM5s6de8j2mZmZXH755XTu3BmbzcZtt91Wbbu33nqLrl274vF46NWrFx9//HHdFy8iIiIiInKAkIarwsJC+vTpw7PPPluj9l6vl+TkZCZPnkyfPn2qbfPtt98yZswYrr32Wn7++WfOO+88zjvvPFasWFGXpYuIiIiIiFTiCOWHjxw5kpEjR9a4fXp6Ok899RQAL730UrVtnnrqKUaMGMFf//pXAB588EHmzZvHv//9b55//vmjL1pERERERKQaIQ1X9eG7775j4sSJlfYNHz78kFMOvV4vXq83+DovLw8An8+Hz+erlzpro6KGcKhF6o76NTKpXyOX+jYyqV8jl/o2MoWiX2vzWREXrrKyskhNTa20LzU1laysrIMe8/DDDzN16tQq++fOnUt0dHSd13ik3nvvvVCXIPVA/RqZ1K+RS30bmdSvkUt9G5kasl+LiooAME3zsG0jLlwdiUmTJlUa7dq+fTvdu3fnuuuuC2FVIiIiIiISLvLz80lISDhkm4gLV82bN2fnzp2V9u3cuZPmzZsf9Bi3243b7Q6+jo2NZevWrcTFxWEYRr3VWlN5eXmkpaWxdetW4uPjQ12O1BH1a2RSv0Yu9W1kUr9GLvVtZApFv5qmSX5+Pi1btjxs24gLVwMHDmT+/PmVlmmfN28eAwcOrPE5bDYbrVu3rofqjk58fLz+cYhA6tfIpH6NXOrbyKR+jVzq28jU0P16uBGrCiENVwUFBaxfvz74euPGjWRkZJCUlESbNm2YNGkS27dvZ+bMmcE2GRkZwWN3795NRkYGLpeL7t27A3Drrbdy2mmn8fjjj3PWWWfx+uuvs3TpUl544YUG/W4iIiIiInJsCWm4Wrp0KaeffnrwdcV1T+PGjWPGjBlkZmayZcuWSsf07ds3+HzZsmXMmjWLtm3bsmnTJgAGDRrErFmzmDx5Mvfccw+dOnVi7ty59OzZs/6/kIiIiIiIHLNCGq4GDx58yFU3ZsyYUWVfTVbpuPjii7n44ouPprSw4na7uf/++ytdFyaNn/o1MqlfI5f6NjKpXyOX+jYyhXu/GmZN0oqIiIiIiIgcki3UBYiIiIiIiEQChSsREREREZE6oHAlIiIiIiJSBxSuRERERERE6oDCVZh79tlnSU9Px+PxMGDAAH744YdQlyS18PDDD3P88ccTFxdHSkoK5513HmvWrKnUpqSkhAkTJtC0aVNiY2O58MIL2blzZ4gqliPxz3/+E8MwKt28XP3aeG3fvp0rrriCpk2bEhUVRa9evVi6dGnwfdM0ue+++2jRogVRUVEMGTKEdevWhbBiORy/38+9995Lu3btiIqKokOHDjz44IOVViBWvzYOixYtYvTo0bRs2RLDMJg7d26l92vSj3v37mXs2LHEx8eTmJjItddeS0FBQQN+C/mjQ/Wrz+fjrrvuolevXsTExNCyZUuuuuoqduzYUekc4dKvCldh7I033mDixIncf//9/PTTT/Tp04fhw4eza9euUJcmNbRw4UImTJjA999/z7x58/D5fAwbNozCwsJgm9tvv50PPviAt956i4ULF7Jjxw4uuOCCEFYttfHjjz/yn//8h969e1far35tnPbt28dJJ52E0+nkk08+4bfffuPxxx+nSZMmwTaPPvooTz/9NM8//zxLliwhJiaG4cOHU1JSEsLK5VAeeeQRpk+fzr///W9WrVrFI488wqOPPsozzzwTbKN+bRwKCwvp06cPzz77bLXv16Qfx44dy8qVK5k3bx4ffvghixYt4vrrr2+oryDVOFS/FhUV8dNPP3Hvvffy008/8e6777JmzRrOOeecSu3Cpl9NCVsnnHCCOWHChOBrv99vtmzZ0nz44YdDWJUcjV27dpmAuXDhQtM0TTMnJ8d0Op3mW2+9FWyzatUqEzC/++67UJUpNZSfn2926tTJnDdvnnnaaaeZt956q2ma6tfG7K677jJPPvnkg74fCATM5s2bm4899lhwX05Ojul2u83Zs2c3RIlyBM466yzzmmuuqbTvggsuMMeOHWuapvq1sQLMOXPmBF/XpB9/++03EzB//PHHYJtPPvnENAzD3L59e4PVLgf3x36tzg8//GAC5ubNm03TDK9+1chVmCotLWXZsmUMGTIkuM9mszFkyBC+++67EFYmRyM3NxeApKQkAJYtW4bP56vUz127dqVNmzbq50ZgwoQJnHXWWZX6D9Svjdn7779P//79ufjii0lJSaFv3768+OKLwfc3btxIVlZWpb5NSEhgwIAB6tswNmjQIObPn8/atWsBWL58OYsXL2bkyJGA+jVS1KQfv/vuOxITE+nfv3+wzZAhQ7DZbCxZsqTBa5Yjk5ubi2EYJCYmAuHVr44G/TSpsT179uD3+0lNTa20PzU1ldWrV4eoKjkagUCA2267jZNOOomePXsCkJWVhcvlCv7jUCE1NZWsrKwQVCk19frrr/PTTz/x448/VnlP/dp4bdiwgenTpzNx4kTuuecefvzxR2655RZcLhfjxo0L9l91/zarb8PX3XffTV5eHl27dsVut+P3+/nHP/7B2LFjAdSvEaIm/ZiVlUVKSkql9x0OB0lJSerrRqKkpIS77rqLMWPGEB8fD4RXvypciTSQCRMmsGLFChYvXhzqUuQobd26lVtvvZV58+bh8XhCXY7UoUAgQP/+/XnooYcA6Nu3LytWrOD5559n3LhxIa5OjtSbb77Ja6+9xqxZs+jRowcZGRncdttttGzZUv0q0oj4fD4uueQSTNNk+vTpoS6nWpoWGKaaNWuG3W6vsrrYzp07ad68eYiqkiN100038eGHH/LVV1/RunXr4P7mzZtTWlpKTk5Opfbq5/C2bNkydu3axZ/+9CccDgcOh4OFCxfy9NNP43A4SE1NVb82Ui1atKB79+6V9nXr1o0tW7YABPtP/zY3Ln/961+5++67ueyyy+jVqxdXXnklt99+Ow8//DCgfo0UNenH5s2bV1kYrKysjL1796qvw1xFsNq8eTPz5s0LjlpBePWrwlWYcrlc9OvXj/nz5wf3BQIB5s+fz8CBA0NYmdSGaZrcdNNNzJkzhy+//JJ27dpVer9fv344nc5K/bxmzRq2bNmifg5jZ555Jr/++isZGRnBrX///owdOzb4XP3aOJ100klVbpewdu1a2rZtC0C7du1o3rx5pb7Ny8tjyZIl6tswVlRUhM1W+Vceu91OIBAA1K+Roib9OHDgQHJycli2bFmwzZdffkkgEGDAgAENXrPUTEWwWrduHV988QVNmzat9H5Y9WuDLp8htfL666+bbrfbnDFjhvnbb7+Z119/vZmYmGhmZWWFujSpoRtuuMFMSEgwFyxYYGZmZga3oqKiYJu//OUvZps2bcwvv/zSXLp0qTlw4EBz4MCBIaxajsSBqwWapvq1sfrhhx9Mh8Nh/uMf/zDXrVtnvvbaa2Z0dLT56quvBtv885//NBMTE8333nvP/OWXX8xzzz3XbNeunVlcXBzCyuVQxo0bZ7Zq1cr88MMPzY0bN5rvvvuu2axZM/N//ud/gm3Ur41Dfn6++fPPP5s///yzCZhPPPGE+fPPPwdXjatJP44YMcLs27evuWTJEnPx4sVmp06dzDFjxoTqK4l56H4tLS01zznnHLN169ZmRkZGpd+nvF5v8Bzh0q8KV2HumWeeMdu0aWO6XC7zhBNOML///vtQlyS1AFS7vfzyy8E2xcXF5o033mg2adLEjI6ONs8//3wzMzMzdEXLEfljuFK/Nl4ffPCB2bNnT9Ptdptdu3Y1X3jhhUrvBwIB89577zVTU1NNt9ttnnnmmeaaNWtCVK3URF5ennnrrbeabdq0MT0ej9m+fXvzb3/7W6VfzNSvjcNXX31V7X9Xx40bZ5pmzfoxOzvbHDNmjBkbG2vGx8ebV199tZmfnx+CbyMVDtWvGzduPOjvU1999VXwHOHSr4ZpHnB7chERERERETkiuuZKRERERESkDihciYiIiIiI1AGFKxERERERkTqgcCUiIiIiIlIHFK5ERERERETqgMKViIiIiIhIHVC4EhERERERqQMKVyIiIiIiInVA4UpERKSOGYbB3LlzQ12GiIg0MIUrERGJKOPHj8cwjCrbiBEjQl2aiIhEOEeoCxAREalrI0aM4OWXX660z+12h6gaERE5VmjkSkREIo7b7aZ58+aVtiZNmgDWlL3p06czcuRIoqKiaN++PW+//Xal43/99VfOOOMMoqKiaNq0Kddffz0FBQWV2rz00kv06NEDt9tNixYtuOmmmyq9v2fPHs4//3yio6Pp1KkT77//fv1+aRERCTmFKxEROebce++9XHjhhSxfvpyxY8dy2WWXsWrVKgAKCwsZPnw4TZo04ccff+Stt97iiy++qBSepk+fzoQJE7j++uv59ddfef/99+nYsWOlz5g6dSqXXHIJv/zyC6NGjWLs2LHs3bu3Qb+niIg0LMM0TTPURYiIiNSV8ePH8+qrr+LxeCrtv+eee7jnnnswDIO//OUvTJ8+PfjeiSeeyJ/+9Ceee+45XnzxRe666y62bt1KTEwMAB9//DGjR49mx44dpKam0qpVK66++mr+/ve/V1uDYRhMnjyZBx98ELACW2xsLJ988omu/RIRiWC65kpERCLO6aefXik8ASQlJQWfDxw4sNJ7AwcOJCMjA4BVq1bRp0+fYLACOOmkkwgEAqxZswbDMNixYwdnnnnmIWvo3bt38HlMTAzx8fHs2rXrSL+SiIg0AgpXIiIScWJiYqpM06srUVFRNWrndDorvTYMg0AgUB8liYhImNA1VyIicsz5/vvvq7zu1q0bAN26dWP58uUUFhYG3//mm2+w2Wx06dKFuLg40tPTmT9/foPWLCIi4U8jVyIiEnG8Xi9ZWVmV9jkcDpo1awbAW2+9Rf/+/Tn55JN57bXX+OGHH/jf//1fAMaOHcv999/PuHHjmDJlCrt37+bmm2/myiuvJDU1FYApU6bwl7/8hZSUFEaOHEl+fj7ffPMNN998c8N+URERCSsKVyIiEnE+/fRTWrRoUWlfly5dWL16NWCt5Pf6669z44030qJFC2bPnk337t0BiI6O5rPPPuPWW2/l+OOPJzo6mgsvvJAnnngieK5x48ZRUlLCk08+yZ133kmzZs246KKLGu4LiohIWNJqgSIickwxDIM5c+Zw3nnnhboUERGJMLrmSkREREREpA4oXImIiIiIiNQBXXMlIiLHFM2GFxGR+qKRKxERERERkTqgcCUiIiIiIlIHFK5ERERERETqgMKViIiIiIhIHVC4EhERERERqQMKVyIiIiIiInVA4UpERERERKQOKFyJiIiIiIjUgf8P79lt2Z/pt8wAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Modèle sauvegardé: lstm_on_fractionnaly_differenciated_WN.pth\n"
          ]
        }
      ],
      "source": [
        "#Let's train the LSTM on the generated data using a ADAM optimizer and MSE loss\n",
        "#parameters of training:\n",
        "#for the optimizer: lr=0.01, scheduler (LROnPlateau): patience=5, eps=1e-6\n",
        "#for the LSTM: 64 hidden size, 2 layers, dropout of 0.2\n",
        "\n",
        "#Let's load the built LSTM model of two layers adapted to our multivariate time series of size k=200\n",
        "lstm_model = LSTMPredictor(\n",
        "    input_size=k,\n",
        "    hidden_size=64,\n",
        "    dropout=0.2)\n",
        "\n",
        "# Configuration (device already set in data preparation)\n",
        "model = lstm_model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, eps=1e-6) #automatic learning rate adjustment\n",
        "\n",
        "num_epochs = 120 #iteration number\n",
        "\n",
        "# Historique des pertes\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(f\"Entraînement sur {device}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # === TRAINING ===\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # === VALIDATION ===\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Affichage\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "              f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"✓ Entraînement terminé\")\n",
        "\n",
        "# Visualisation of loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.title('Training History')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Let's save the trained model\n",
        "torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_loss': train_losses[-1],\n",
        "    'val_loss': val_losses[-1],\n",
        "}, 'lstm_on_fractionnaly_differenciated_WN.pth')\n",
        "\n",
        "print(\"✓ Modèle sauvegardé: lstm_on_fractionnaly_differenciated_WN.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pWdnSHhVCqvx",
      "metadata": {
        "id": "pWdnSHhVCqvx"
      },
      "source": [
        "The validation loss seems to have reached a plateau at around 50 iterations with a loss around 1.12. We can stop our training at 50 iterations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2405fe1a",
      "metadata": {
        "id": "2405fe1a"
      },
      "source": [
        "#### Let's verify the long memory property in the LSTM trained"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xEg-OWBSK_Gj",
      "metadata": {
        "id": "xEg-OWBSK_Gj"
      },
      "source": [
        "First, let's extract the last layer of our trained LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "DJOspbk-AdY3",
      "metadata": {
        "id": "DJOspbk-AdY3",
        "outputId": "46663749-824b-479d-995e-21ee11be24a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden representation shape: (13056, 64)\n",
            "Number of time steps in test: 13056\n",
            "Hidden state dimension: 64\n"
          ]
        }
      ],
      "source": [
        "#Loading the trained model\n",
        "model.load_state_dict(torch.load('lstm_on_fractionnaly_differenciated_WN.pth')[\"model_state_dict\"])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "hidden_states_val = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in val_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        lstm_out, (h_n, c_n) = model.lstm(X_batch)\n",
        "        hidden_states_val.append(h_n[-1].cpu())\n",
        "\n",
        "hidden_rep = torch.cat(hidden_states_val, dim=0).numpy()\n",
        "\n",
        "print(f\"Hidden representation shape: {hidden_rep.shape}\")\n",
        "print(f\"Number of time steps in test: {hidden_rep.shape[0]}\")\n",
        "print(f\"Hidden state dimension: {hidden_rep.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117f8191",
      "metadata": {
        "id": "117f8191"
      },
      "source": [
        "\n",
        "\n",
        "## Theoretical Framework: VARFIMA Behavior in LSTMs\n",
        "\n",
        "If an LSTM successfully captures long memory, it should behave like a **VARFIMA model**. Let's examine what this means:\n",
        "\n",
        "### VARFIMA Model\n",
        "A VARFIMA process is defined as:\n",
        "$$\\Psi(B) X_t = Z_t$$\n",
        "\n",
        "where the inverse filter is:\n",
        "$$\\Psi(B) = (1-B)^d$$\n",
        "\n",
        "and the inverse operation is:\n",
        "$$X_t = \\Psi(B)^{-1} Z_t = (1-B)^{-d} Z_t$$\n",
        "\n",
        "### Test 1: Fractionally Differenced Input\n",
        "\n",
        "Our genereated input is a **fractionally differenced white noise**:\n",
        "$$\\tilde{X}_t = (1-B)^d Z_t$$\n",
        "\n",
        "If the LSTM has learned the VARFIMA structure, its hidden state should perform the inverse operation:\n",
        "$$h_t = \\Psi(\\tilde{X}_t) = (1-B)^{-d} \\tilde{X}_t = (1-B)^{-d} (1-B)^d Z_t = Z_t$$\n",
        "\n",
        "**Expected result**: If the LSTM has long memory property, the hidden state $h_t$ should equal white noise $Z_t$, which has **$d = 0$**, meaning that the LSTM sucessfully captured and removed the long memory in the differenciated white noise.\n",
        "\n",
        "#### Hypothesis Test\n",
        "\n",
        "We test:\n",
        "- **H0**: $d = 0$ (hidden states have no long memory, LSTM has long memory)\n",
        "- **H1**: $d \\neq 0$ (hidden states have long memory, LSTM does not have long memory)\n",
        "\n",
        "The test uses the GSE statistics to estimate the long memory parameter $d$ from the hidden representation and returns a p-value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "_N4d4SBPHSUj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N4d4SBPHSUj",
        "outputId": "27170385-97b9-4db2-d1cc-781e197a9ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST 1: LSTM trained on Fractionally Differenced White Noise\n",
            "  Total long memory: -0.008825\n",
            "  Std deviation: 0.062500\n",
            "  p-value (H0: d=0): 5.5614e-01\n",
            "\n",
            "Conclusion:\n",
            "   H0 is accepted (p ≥ 0.05): d ≈ 0\n",
            " → Hidden states does not contain long memory anymore --> LSTM has long memory property\n"
          ]
        }
      ],
      "source": [
        "# Test long memory on LSTM hidden states\n",
        "\n",
        "hidden_rep_transposed = hidden_rep.T\n",
        "\n",
        "tot_mem_hidden, std_var_hidden, p_val_hidden = compute_total_memory(\n",
        "    hidden_rep_transposed)\n",
        "\n",
        "\n",
        "print(f\"TEST 1: LSTM trained on Fractionally Differenced White Noise\")\n",
        "print(f\"  Total long memory: {tot_mem_hidden:.6f}\")\n",
        "print(f\"  Std deviation: {np.sqrt(std_var_hidden):.6f}\")\n",
        "print(f\"  p-value (H0: d=0): {p_val_hidden:.4e}\")\n",
        "print(f\"\\nConclusion:\")\n",
        "if p_val_hidden < 0.05:\n",
        "    print(f\"  ✗ H0 is rejected (p < 0.05): d ≠ 0\")\n",
        "    print(f\"  → Hidden states still contains long memory --> LSTM has no long memory property\")\n",
        "else:\n",
        "    print(f\"   H0 is accepted (p ≥ 0.05): d ≈ 0\")\n",
        "    print(f\" → Hidden states does not contain long memory anymore --> LSTM has long memory property\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b2cc38",
      "metadata": {
        "id": "a3b2cc38"
      },
      "source": [
        "We ran the test on the last layer of our LSTM and the test gave a long memory statistic d = 0.0047 and a non significative p-value around 0.7\n",
        "\n",
        "We can't reject the hypothesis of absence of long memory. The trained LSTM failed to adapt the behaviour of a VARFIMA. It means that it does not have long memory property."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd1257a0",
      "metadata": {
        "id": "cd1257a0"
      },
      "source": [
        "## Test 2: Long memory transformation of white noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11cd35e",
      "metadata": {
        "id": "e11cd35e"
      },
      "source": [
        "### Generation of a White Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5d8f17ef",
      "metadata": {
        "id": "5d8f17ef",
        "outputId": "52e073a7-a35d-4d74-e0dc-b2cd7369b63a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated White Noise:\n",
            "  Shape: torch.Size([200, 65536])\n",
            "  Mean: -0.000262 (should be ~0)\n",
            "  Std: 1.000111 (should be ~1)\n",
            "  Min/Max: [-5.4476, 5.6275]\n"
          ]
        }
      ],
      "source": [
        "# Generate pure White Noise\n",
        "np.random.seed(42)\n",
        "k_wn = 200\n",
        "T_wn = 2**16\n",
        "WN_seq = torch.randn(k_wn, T_wn)  # Pure white noise: N(0,1)\n",
        "\n",
        "print(f\"\\nGenerated White Noise:\")\n",
        "print(f\"  Shape: {WN_seq.shape}\")\n",
        "print(f\"  Mean: {WN_seq.mean():.6f} (should be ~0)\")\n",
        "print(f\"  Std: {WN_seq.std():.6f} (should be ~1)\")\n",
        "print(f\"  Min/Max: [{WN_seq.min():.4f}, {WN_seq.max():.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "24658e8a",
      "metadata": {
        "id": "24658e8a",
        "outputId": "fc5699a2-421b-4b1b-9a04-16264335ec8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 12.45 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.98 GiB is free. Process 2770 has 12.76 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 45.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-879277169.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create supervised dataset with rolling window process on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m X_wn, y_wn = unfold_sequence_to_supervised_dataset(\n\u001b[0m\u001b[1;32m      3\u001b[0m     WN_seq, seq_length=256, forecast_horizon=1, device=device)\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTest 2 dataset created on {device}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  X memory: {X_wn.element_size() * X_wn.nelement() / 1e9:.2f} GB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-721688378.py\u001b[0m in \u001b[0;36munfold_sequence_to_supervised_dataset\u001b[0;34m(data, seq_length, forecast_horizon, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforecast_horizon\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast_horizon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.45 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.98 GiB is free. Process 2770 has 12.76 GiB memory in use. Of the allocated memory 12.58 GiB is allocated by PyTorch, and 45.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Create supervised dataset with rolling window process on GPU\n",
        "X_wn, y_wn = unfold_sequence_to_supervised_dataset(\n",
        "    WN_seq, seq_length=256, forecast_horizon=1, device=device)\n",
        "print(f\"\\nTest 2 dataset created on {device}\")\n",
        "print(f\"  X memory: {X_wn.element_size() * X_wn.nelement() / 1e9:.2f} GB\")\n",
        "print(f\"  y memory: {y_wn.element_size() * y_wn.nelement() / 1e9:.2f} GB\")\n",
        "\n",
        "\n",
        "#Train/test split dataset\n",
        "full_dataset_wn = TensorDataset(X_wn, y_wn)\n",
        "train_size_wn = int(0.8 * len(full_dataset_wn))\n",
        "val_size_wn = len(full_dataset_wn) - train_size_wn\n",
        "\n",
        "train_dataset_wn, val_dataset_wn = torch.utils.data.random_split(\n",
        "    full_dataset_wn, [train_size_wn, val_size_wn]\n",
        ")\n",
        "\n",
        "train_loader_wn = DataLoader(train_dataset_wn, batch_size=32, shuffle=True)\n",
        "val_loader_wn = DataLoader(val_dataset_wn, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"\\nDataset shapes:\")\n",
        "print(f\"  X shape: {X_wn.shape}\")\n",
        "print(f\"  y shape: {y_wn.shape}\")\n",
        "print(f\"  Train samples: {len(train_dataset_wn)}\")\n",
        "print(f\"  Val samples: {len(val_dataset_wn)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd9c8bd",
      "metadata": {
        "id": "6cd9c8bd"
      },
      "outputs": [],
      "source": [
        "#Let's train the LSTM on the training set using a ADAM optimizer and MSE loss\n",
        "#parameters of training:\n",
        "#for the optimizer: lr=0.01, scheduler (LROnPlateau): patience=5, eps=1e-6\n",
        "#for the LSTM: 64 hidden size, 2 layers, dropout of 0.2\n",
        "\n",
        "#Let's load the built LSTM model of two layers adapted to our multivariate time series of size k=200\n",
        "lstm_model = LSTMPredictor(\n",
        "    input_size=k,\n",
        "    hidden_size=64,\n",
        "    dropout=0.2)\n",
        "\n",
        "# Configuration (device already set in data preparation)\n",
        "model = lstm_model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, eps=1e-6) #automatic learning rate adjustment\n",
        "\n",
        "num_epochs = 100 #iteration number\n",
        "\n",
        "# Historique des pertes\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(f\"Entraînement sur {device}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # === TRAINING ===\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for X_batch, y_batch in train_loader_wn:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(train_loader_wn)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # === VALIDATION ===\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader_wn:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader_wn)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Affichage\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "              f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"✓ Entraînement terminé\")\n",
        "\n",
        "# Visualisation of loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.title('Training History')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Let's save the trained model\n",
        "torch.save({\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_loss': train_losses[-1],\n",
        "    'val_loss': val_losses[-1],\n",
        "}, 'lstm_on_WN.pth')\n",
        "\n",
        "print(\"✓ Modèle sauvegardé: lstm_on_WN.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a70ecd6",
      "metadata": {
        "id": "3a70ecd6"
      },
      "outputs": [],
      "source": [
        "#Loading the trained model\n",
        "model.load_state_dict(torch.load('lstm_on_WN.pth')[\"model_state_dict\"])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "#Extract hidden states on validation set\n",
        "hidden_states_val = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in val_loader_wn:\n",
        "        X_batch = X_batch.to(device)\n",
        "        lstm_out, (h_n, c_n) = model.lstm(X_batch)\n",
        "        hidden_states_val.append(h_n[-1].cpu())\n",
        "\n",
        "hidden_rep = torch.cat(hidden_states_val, dim=0).numpy()\n",
        "\n",
        "print(f\"Hidden representation shape: {hidden_rep.shape}\")\n",
        "print(f\"Number of time steps in test: {hidden_rep.shape[0]}\")\n",
        "print(f\"Hidden state dimension: {hidden_rep.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7295ac85",
      "metadata": {
        "id": "7295ac85"
      },
      "outputs": [],
      "source": [
        "# Test long memory on LSTM hidden states\n",
        "\n",
        "hidden_rep_transposed = hidden_rep.T\n",
        "\n",
        "tot_mem_hidden, std_var_hidden, p_val_hidden = compute_total_memory(\n",
        "    hidden_rep_transposed)\n",
        "\n",
        "print(f\"TEST 2: Transformation of WN by LSTM\")\n",
        "print(f\"  Total long memory: {tot_mem_hidden:.6f}\")\n",
        "print(f\"  Std deviation: {np.sqrt(std_var_hidden):.6f}\")\n",
        "print(f\"  p-value (H0: d=0): {p_val_hidden:.4e}\")\n",
        "print(f\"\\nConclusion:\")\n",
        "if p_val_hidden < 0.05:\n",
        "    print(f\"  ✗ H0 is rejected (p < 0.05): d ≠ 0\")\n",
        "    print(f\"  →  LSTM has long memory property\")\n",
        "else:\n",
        "    print(f\"   H0 is accepted (p ≥ 0.05): d ≈ 0\")\n",
        "    print(f\" →  LSTM has no long memory property\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fad90eef",
      "metadata": {
        "id": "fad90eef"
      },
      "source": [
        "### Monte Carlo Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10051f49",
      "metadata": {
        "id": "10051f49"
      },
      "outputs": [],
      "source": [
        "#n=100 experiment for each test"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}